{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06fdef3c-c7c5-402c-9f82-44f8a2ec6d19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Obtendo os dados e separando entre treino e teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "149f2c3e-df43-45b1-860d-52c8991f998d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ded77fde-43c8-4776-82fc-7264fd7618d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow>=3.0 --upgrade\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7bdfe8ba-9a3f-44b7-91d2-721dab322103",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, lit, rand, count, mean, stddev\n",
    "from pyspark.sql.window import Window\n",
    "import mlflow\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11471099-d176-4b69-a77e-a4ecaad7b3dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Obtendo os dados\n",
    "Utilizando o _Unity Catalog_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae25f34-9341-4fdd-931e-3c87975b0df3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.table(\"my_catalog.default.creditcard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47aaafb9-8bc9-4b87-a16c-f481f89561f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2524dedf-bee6-48a8-a401-dcb783a35e9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Credit Card Fraud Detection - linhas:\",df.count(),\"colunas:\",len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8620d4f-362b-4004-8bf8-91cb83138094",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08857459-dcab-405b-90e4-99dbd02c5889",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class_distribution = df.groupBy(\"Class\").agg(\n",
    "    count(\"*\").alias(\"count\"),\n",
    "    (count(\"*\") / df.count() * 100).alias(\"%\")\n",
    ").orderBy(\"Class\")\n",
    "\n",
    "print(\"Distribuição da Classe Target (Fraudes):\")\n",
    "display(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90df2bb6-7372-4637-8d52-8a5fbb821fd4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    " Classe | Descrição    | Count   | %          |\n",
    "-------|--------------|---------|------------|\n",
    " 0     | Legítimas    | 284,315 | 99.83%     |\n",
    " 1     | Fraudulentas | 492     | 0.17%      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277af880-8b20-480a-9280-f71f6b4c5e12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb60f400-71c9-4c8f-86ae-80d4c343b1e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Criando Conjuntos de Treino e Teste\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f12275a5-4727-4177-8c2c-2f0392ec62ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Função de divisão aleatória (RandomSplit) sem estratificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4d24dcc0-4461-4e01-97ea-3304953b95e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_random_split(df, target_col=\"Class\", test_ratio=0.2, seed=42):\n",
    "    \n",
    "    train_set, test_set = df.randomSplit([1-test_ratio, test_ratio], seed=seed)\n",
    "    \n",
    "    print(f\"Divisão aleatória concluída!\")\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa22c36f-5570-448b-b4c6-7de714109ec1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Função de divisão aleatória (RandomSplit) com estratificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "493823a0-1fe6-4e9a-9be6-614a31451c87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# função de divisão estratificada\n",
    "def create_stratified_split(df, target_col=\"Class\", test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    cria uma divisão estratificada mantendo a proporção de fraudes\n",
    "    \"\"\"\n",
    "    print(\"Iniciando divisão...\")\n",
    "    \n",
    "    # separar os dados em fraudes e transações normais\n",
    "    fraud_df = df.filter(col(target_col) == 1)\n",
    "    normal_df = df.filter(col(target_col) == 0)\n",
    "    \n",
    "    print(f\"Transações normais: {normal_df.count():,}\")\n",
    "    print(f\"Transações fraudulentas: {fraud_df.count():,}\")\n",
    "    \n",
    "    # divide cada grupo separadamente\n",
    "    fraud_train, fraud_test = fraud_df.randomSplit([1-test_ratio, test_ratio], seed=seed)\n",
    "    normal_train, normal_test = normal_df.randomSplit([1-test_ratio, test_ratio], seed=seed)\n",
    "    \n",
    "    # combina os resultados\n",
    "    train_set = normal_train.union(fraud_train)\n",
    "    test_set = normal_test.union(fraud_test)\n",
    "    \n",
    "    print(\"Divisão estratificada concluída! :)\")\n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "195374b2-a6e1-4760-a7a8-7af775a1294f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# divisão dos conjuntos\n",
    "#train_set, test_set = create_stratified_split(df, test_ratio=0.2, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eabc169c-2b44-45c1-8b3c-dd85a9fa5eee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Função de divisão com estratificação e determinística ### \n",
    "<br>\n",
    "A ideia aqui é fazer com que o mesmo id (a mesma transação) vá sempre para o mesmo conjunto (teste ou treino)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "350eee9f-f5cf-4c09-b5e2-75e38870747d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def create_deterministic_stratified_split(df, target_col=\"Class\", test_ratio=0.2, seed=42):\n",
    "    \"\"\"\n",
    "    cria uma divisão estratificada determinística usando hash estável\n",
    "    garante que a mesma linha sempre vai para o mesmo conjunto\n",
    "    \"\"\"\n",
    "    print(\"Iniciando divisão determinística...\")\n",
    "    \n",
    "    # cria um identificador único estável para cada linha\n",
    "    # usa colunas existentes para criar um hash determinístico\n",
    "    df_with_id = df.withColumn(\n",
    "        \"row_hash\", \n",
    "        F.hash(F.concat_ws(\"|\", *df.columns))\n",
    "    )\n",
    "    \n",
    "    # adiciona um índice determinístico baseado no hash\n",
    "    window = Window.orderBy(\"row_hash\")\n",
    "    df_with_index = df_with_id.withColumn(\"deterministic_index\", F.row_number().over(window))\n",
    "    \n",
    "    # separa os dados em fraudes e normais\n",
    "    fraud_df = df_with_index.filter(F.col(target_col) == 1)\n",
    "    normal_df = df_with_index.filter(F.col(target_col) == 0)\n",
    "    \n",
    "    print(f\"Transações normais: {normal_df.count():,}\")\n",
    "    print(f\"Transações fraudulentas: {fraud_df.count():,}\")\n",
    "    \n",
    "    # função para divisão determinística baseada no índice\n",
    "    def split_deterministic(df, ratio, seed):\n",
    "        total_count = df.count()\n",
    "        test_count = int(total_count * ratio)\n",
    "        \n",
    "        # ordenar deterministicamente e pegar os primeiros para teste\n",
    "        test_set = df.orderBy(\"deterministic_index\").limit(test_count)\n",
    "        \n",
    "        # o restante vai para treino\n",
    "        train_set = df.join(test_set, \"deterministic_index\", \"left_anti\")\n",
    "        \n",
    "        return train_set, test_set\n",
    "    \n",
    "    # divide cada grupo\n",
    "    fraud_train, fraud_test = split_deterministic(fraud_df, test_ratio, seed)\n",
    "    normal_train, normal_test = split_deterministic(normal_df, test_ratio, seed)\n",
    "    \n",
    "    # combina os resultados e remove colunas auxiliares\n",
    "    train_set = normal_train.union(fraud_train).drop(\"row_hash\", \"deterministic_index\")\n",
    "    test_set = normal_test.union(fraud_test).drop(\"row_hash\", \"deterministic_index\")\n",
    "    \n",
    "    # valida as proporções\n",
    "    train_fraud_rate = train_set.filter(F.col(target_col) == 1).count() / train_set.count()\n",
    "    test_fraud_rate = test_set.filter(F.col(target_col) == 1).count() / test_set.count()\n",
    "    original_fraud_rate = df.filter(F.col(target_col) == 1).count() / df.count()\n",
    "    \n",
    "    print(f\"\\nValidação da divisão:\")\n",
    "    print(f\"Fraude original: {original_fraud_rate:.4f}\")\n",
    "    print(f\"Fraude treino:   {train_fraud_rate:.4f}\")\n",
    "    print(f\"Fraude teste:    {test_fraud_rate:.4f}\")\n",
    "    print(f\"Divisão determinística concluída! :)\")\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7ab8766-590d-4670-a766-1b8f9ef242a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Comparação dos métodos\n",
    "### \n",
    "Teste entre aleatório, estratificado e determinístico. (validar afirmação do livro para o nosso dataset e escolher melhor abordagem.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "93aef1db-6312-4160-beca-102a1d640d6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def validate_all_splits(df, target_col=\"Class\"):\n",
    "    \"\"\"\n",
    "    valida todos os splits e compara os 3 métodos de divisão e salva no MLflow\n",
    "    \"\"\"\n",
    "    \n",
    "    mlflow.set_experiment(experiment_id=\"1059645231822150\")\n",
    "    \n",
    "    with mlflow.start_run(run_name=\"comparacao_metodos_divisao\"):\n",
    "        print(\"Comparação dos métodos de divisão: \\n\")\n",
    "\n",
    "        total = df.count()\n",
    "        fraud_count = df.filter(F.col(target_col) == 1).count()\n",
    "        real_fraud_rate = fraud_count / total\n",
    "        \n",
    "        print(f\"Dataset original: {total:,} transações\")\n",
    "        print(f\"Taxa real de fraudes: {real_fraud_rate:.6f}\")\n",
    "        \n",
    "        # criar splits com todos os métodos\n",
    "        print(\"\\nCriando splits...\")\n",
    "        \n",
    "        # aleatório simples\n",
    "        train_rand, test_rand = create_random_split(df, target_col)\n",
    "        \n",
    "        # estratificado com randomSplit\n",
    "        train_strat, test_strat = create_stratified_split(df, target_col)\n",
    "        \n",
    "        # estratificado determinístico\n",
    "        train_det, test_det = create_deterministic_stratified_split(df, target_col)\n",
    "        \n",
    "        # função para calcular estatísticas\n",
    "        def get_split_stats(train_set, test_set, method_name):\n",
    "            train_total = train_set.count()\n",
    "            train_fraud = train_set.filter(F.col(target_col) == 1).count()\n",
    "            train_fraud_rate = train_fraud / train_total if train_total > 0 else 0\n",
    "            train_error = abs(train_fraud_rate - real_fraud_rate) / real_fraud_rate * 100\n",
    "            \n",
    "            test_total = test_set.count()\n",
    "            test_fraud = test_set.filter(F.col(target_col) == 1).count()\n",
    "            test_fraud_rate = test_fraud / test_total if test_total > 0 else 0\n",
    "            test_error = abs(test_fraud_rate - real_fraud_rate) / real_fraud_rate * 100\n",
    "            \n",
    "            return {\n",
    "                'method': method_name,\n",
    "                'train_total': train_total,\n",
    "                'train_fraud': train_fraud,\n",
    "                'train_rate': train_fraud_rate,\n",
    "                'train_error': train_error,\n",
    "                'test_total': test_total,\n",
    "                'test_fraud': test_fraud,\n",
    "                'test_rate': test_fraud_rate,\n",
    "                'test_error': test_error,\n",
    "                'max_error': max(train_error, test_error),\n",
    "                'avg_error': (train_error + test_error) / 2\n",
    "            }\n",
    "        \n",
    "        # coletar estatísticas de todos os métodos\n",
    "        methods = [\n",
    "            get_split_stats(train_rand, test_rand, \"ALEATORIO\"),\n",
    "            get_split_stats(train_strat, test_strat, \"ESTRATIFICADO\"),\n",
    "            get_split_stats(train_det, test_det, \"DETERMINISTICO\")\n",
    "        ]\n",
    "        \n",
    "        # tabelinha\n",
    "        print(f\"{'METODO':<15} {'CONJUNTO':<8} {'TAMANHO':<10} {'FRAUDES':<8} {'TAXA':<10} {'ERRO %':<8}\")\n",
    "        print(f\"{'-'*60}\")\n",
    "        \n",
    "        for method in methods:\n",
    "            print(f\"{method['method']:<15} {'Treino':<8} {method['train_total']:<10,} {method['train_fraud']:<8,} {method['train_rate']:.6f}  {method['train_error']:>6.2f}%\")\n",
    "            print(f\"{'':<15} {'Teste':<8} {method['test_total']:<10,} {method['test_fraud']:<8,} {method['test_rate']:.6f}  {method['test_error']:>6.2f}%\")\n",
    "            print(f\"{'-'*60}\")\n",
    "        \n",
    "        # encontra o melhor método\n",
    "        best_method = min(methods, key=lambda x: x['max_error'])\n",
    "        print(f\"\\nMelhor metodo: {best_method['method']} ({best_method['max_error']:.2f}% erro)\")\n",
    "        \n",
    "        # MLFlow logging\n",
    "        \n",
    "        # parâmetros gerais\n",
    "        mlflow.log_params({\n",
    "            \"dataset_total\": total,\n",
    "            \"fraudes_total\": fraud_count,\n",
    "            \"taxa_fraudes_real\": float(real_fraud_rate),\n",
    "            \"proporcao_teste\": 0.2,\n",
    "            \"seed\": 42,\n",
    "            \"melhor_metodo\": best_method['method'],\n",
    "            \"aleatorio_erro_max\": float(methods[0]['max_error']),\n",
    "            \"estratificado_erro_max\": float(methods[1]['max_error']),\n",
    "            \"deterministico_erro_max\": float(methods[2]['max_error'])\n",
    "        })\n",
    "        \n",
    "        # métricas para cada método\n",
    "        metrics = {}\n",
    "        for method in methods:\n",
    "            prefix = method['method'].lower()\n",
    "            metrics.update({\n",
    "                f\"{prefix}_treino_tamanho\": method['train_total'],\n",
    "                f\"{prefix}_treino_fraudes\": method['train_fraud'],\n",
    "                f\"{prefix}_treino_taxa\": float(method['train_rate']),\n",
    "                f\"{prefix}_treino_erro\": float(method['train_error']),\n",
    "                f\"{prefix}_teste_tamanho\": method['test_total'],\n",
    "                f\"{prefix}_teste_fraudes\": method['test_fraud'],\n",
    "                f\"{prefix}_teste_taxa\": float(method['test_rate']),\n",
    "                f\"{prefix}_teste_erro\": float(method['test_error']),\n",
    "                f\"{prefix}_erro_maximo\": float(method['max_error']),\n",
    "                f\"{prefix}_erro_medio\": float(method['avg_error'])\n",
    "            })\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        \n",
    "        # tags\n",
    "        mlflow.set_tags({\n",
    "            \"projeto\": \"detecao_fraudes_tcc\",\n",
    "            \"fase\": \"preprocessamento\",\n",
    "            \"tipo_analise\": \"comparacao_metodos_divisao\",\n",
    "            \"unidade\": \"univesp\"\n",
    "        })\n",
    "        \n",
    "        print(\"\\nBoa!Comparação salva no MLflow! :)\")\n",
    "        \n",
    "        return {\n",
    "            'real_rate': real_fraud_rate,\n",
    "            'methods': {m['method']: m for m in methods},\n",
    "            'best_method': best_method['method'],\n",
    "            'mlflow_run_id': mlflow.active_run().info.run_id\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4f33cc78-cc75-460e-aea9-689c25fcea43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comparison = validate_all_splits(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9df05694-553f-4d9c-a1a7-777cd68a960a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Método         | Conjunto | Tamanho   | Fraudes | Taxa       | Erro %  |\n",
    "|----------------|----------|-----------|---------|------------|---------|\n",
    "| Aleatório      | Treino   | 227,940   | 400     | 0.001755   | 1.58%   |\n",
    "| Aleatório               | Teste    | 56,867    | 92      | 0.001618   | 6.35%   |\n",
    "| Estratificado  | Treino   | 227,948   | 390     | 0.001711   | 0.96%   |\n",
    "| Estratificado               | Teste    | 56,859    | 102     | 0.001794   | 3.85%   |\n",
    "| Determinístico | Treino   | 227,846   | 394     | 0.001729   | 0.10%   |\n",
    "| Determinístico               | Teste    | 56,961    | 98      | 0.001720   | 0.41%   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e019c88d-5166-4903-b83a-cddcb79aa3f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Usar o melhor método de divisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5041e22c-353b-4430-b5d9-68bcd68871cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#if comparison['best_method'] == \"DETERMINISTICO\":\n",
    "#   train_set, test_set = create_deterministic_stratified_split(df)\n",
    "#elif comparison['best_method'] == \"ESTRATIFICADO\":\n",
    "#    train_set, test_set = create_stratified_split(df)\n",
    "#else:\n",
    "#    train_set, test_set = create_random_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5060c033-ecd5-4ea6-8a19-ef27395ae9dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_set, test_set = create_deterministic_stratified_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba2c6dd2-a3ab-4083-80a3-378cfd893464",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Validar a divisão escolhida\n",
    "Vamos validar se a nossa variável alvo ficou bem dividida entre os splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a392f4dd-0a1c-446c-a2a4-bfc500844edc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# função para validação das divisões\n",
    "def validate_split_quality(train_set, test_set, target_col=\"Class\"):\n",
    "\n",
    "    \"\"\"\n",
    "    valida se a divisão manteve as proporções corretas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Iniciando validação da divisão...\")\n",
    "\n",
    "    # estatísticas\n",
    "    train_total = train_set.count()\n",
    "    test_total = test_set.count()\n",
    "    overall_total = train_total + test_total\n",
    "    \n",
    "    train_fraud = train_set.filter(col(target_col) == 1).count()\n",
    "    test_fraud = test_set.filter(col(target_col) == 1).count()\n",
    "    overall_fraud = train_fraud + test_fraud\n",
    "    \n",
    "    # proporções\n",
    "    train_ratio = train_fraud / train_total\n",
    "    test_ratio = test_fraud / test_total\n",
    "    overall_ratio = overall_fraud / overall_total\n",
    "    \n",
    "    print(\"Validação da divisão estratificada determinística: \\n\")\n",
    "    print(f\"Tamanhos dos conjuntos:\")\n",
    "    print(f\"Treino: {train_total:,} transações ({train_total/overall_total*100:.1f}%)\")\n",
    "    print(f\"Teste: {test_total:,} transações ({test_total/overall_total*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n Proporção de fraudes:\")\n",
    "    print(f\"Geral: {overall_ratio:.6f} ({overall_fraud:,} fraudes)\")\n",
    "    print(f\"Treino: {train_ratio:.6f} ({train_fraud:,} fraudes)\")\n",
    "    print(f\"Teste: {test_ratio:.6f} ({test_fraud:,} fraudes)\")\n",
    "    \n",
    "    # avaliar qualidade\n",
    "    diff_train = abs(train_ratio - overall_ratio)\n",
    "    diff_test = abs(test_ratio - overall_ratio)\n",
    "    total_error = diff_train + diff_test\n",
    "    \n",
    "    print(f\"\\n Qualidade da estratificação:\")\n",
    "    print(f\"Diferença no treino: {diff_train:.6f}\")\n",
    "    print(f\"Diferença no teste: {diff_test:.6f}\")\n",
    "    print(f\"Erro total: {total_error:.6f}\")\n",
    "    \n",
    "    if total_error < 0.001:\n",
    "        print(\"Proporções muito consistentes\")\n",
    "    elif total_error < 0.005:\n",
    "        print(\"Proporções consistentes\")\n",
    "    else:\n",
    "        print(\"Verificar a divisão\")\n",
    "    \n",
    "    return {\n",
    "        'train_size': train_total,\n",
    "        'test_size': test_total,\n",
    "        'total_size': overall_total,\n",
    "        'train_fraud_count': train_fraud,\n",
    "        'test_fraud_count': test_fraud,\n",
    "        'total_fraud_count': overall_fraud,\n",
    "        'train_fraud_ratio': train_ratio,\n",
    "        'test_fraud_ratio': test_ratio,\n",
    "        'overall_fraud_ratio': overall_ratio,\n",
    "        'stratification_error': total_error\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2b9ccd7e-f239-4663-a1ad-e9c9f95a82cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "validation_stats = validate_split_quality(train_set, test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "459fa7d4-2d66-4f8d-a86a-9d4e7e0366c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Salvando os Conjuntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8688a97c-4bf7-43a7-8dd6-5ea5e47fda6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# gera timestamp para versionamento\n",
    "#from datetime import datetime\n",
    "#timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# define nomes das tabelas\n",
    "#tabela_treino = f\"my_catalog.default.creditcard_treino_v{timestamp}\"\n",
    "#tabela_teste = f\"my_catalog.default.creditcard_teste_v{timestamp}\"\n",
    "\n",
    "# salva conjuntos\n",
    "#train_set.write.mode(\"overwrite\").saveAsTable(tabela_treino)\n",
    "#print(\"Treino salvo com sucesso!\")\n",
    "\n",
    "#test_set.write.mode(\"overwrite\").saveAsTable(tabela_teste) \n",
    "#print(\"Teste salvo com sucesso!\")\n",
    "\n",
    "# cria dicionário com os nomes para usar depois\n",
    "#nomes_tabelas = {\n",
    "#    'treino': tabela_treino,\n",
    "#    'teste': tabela_teste\n",
    "#}\n",
    "\n",
    "#print(f\"\\n Datasets salvos:\")\n",
    "#print(f\"Treino: {tabela_treino}\")\n",
    "#print(f\"Teste: {tabela_teste}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2729b5c0-ecc4-4965-9e8f-73b2f7f7a975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tabela_treino = \"my_catalog.default.creditcard_treino_tcc\"\n",
    "tabela_teste = \"my_catalog.default.creditcard_teste_tcc\"\n",
    "\n",
    "train_set.write.mode(\"overwrite\").saveAsTable(tabela_treino)\n",
    "test_set.write.mode(\"overwrite\").saveAsTable(tabela_teste)\n",
    "\n",
    "print(f\"\\n Conjuntos salvos:\")\n",
    "print(f\"Treino: {tabela_treino}\")\n",
    "print(f\"Teste: {tabela_teste}\")\n",
    "print(f\"Total treino: {train_set.count():,} transações\")\n",
    "print(f\"Total teste: {test_set.count():,} transações\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78c8fae-614c-4d6b-b65e-1ed89032bae2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#train_set = spark.read.table(tabela_treino)\n",
    "#test_set = spark.read.table(tabela_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "35074b0f-b455-426c-a4ca-3df850a812de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# test_set = spark.read.table(\"my_catalog.default.creditcard_teste_tcc\")\n",
    "# df_test = test_set.toPandas()\n",
    "# print(f\"Número de linhas: {df_test.shape[0]}\")\n",
    "# print(f\"Número de colunas: {df_test.shape[1]}\")\n",
    "# fraud_count_test = df_test[df_test['Class'] == 1].shape[0]\n",
    "# legit_count_test = df_test[df_test['Class'] == 0].shape[0]\n",
    "# print(f\"Número de transações fraudulentas: {fraud_count_test}\")\n",
    "# print(f\"Número de transações legítimas: {legit_count_test}\")\n",
    "# fraud_pct_test = fraud_count_test / df_test.shape[0] * 100\n",
    "# print(f\"Percentual de transações fraudulentas: {fraud_pct_test:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "15c9fd30-848c-4199-826e-8851bb0c3098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# train_count = train_set.count()\n",
    "# test_count = test_set.count()\n",
    "# total_count = train_count + test_count\n",
    "# train_pct = train_count / total_count * 100\n",
    "# test_pct = test_count / total_count * 100\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# axes[0].pie([train_count, test_count], labels=['Treino', 'Teste'], autopct=lambda pct: f'{pct:.2f}%\\n({int(pct/100*total_count):,})', colors=['skyblue', 'salmon'], startangle=90, textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "# axes[0].set_title('\\nProporção de Transações (Treino vs Teste)\\n', fontsize=14, fontweight='bold')\n",
    "\n",
    "# train_counts = train_set.groupBy(\"Class\").count().toPandas()\n",
    "# test_counts = test_set.groupBy(\"Class\").count().toPandas()\n",
    "# train_vals = train_counts.sort_values('Class')['count'].values\n",
    "# test_vals = test_counts.sort_values('Class')['count'].values\n",
    "# train_total = train_vals.sum()\n",
    "# test_total = test_vals.sum()\n",
    "# train_fraud_pct = train_vals[1] / train_total * 100\n",
    "# test_fraud_pct = test_vals[1] / test_total * 100\n",
    "\n",
    "# bars = axes[1].bar(['Treino', 'Teste'], [train_fraud_pct, test_fraud_pct], color=['skyblue', 'salmon'])\n",
    "# axes[1].set_ylabel('% Fraude')\n",
    "# axes[1].set_title('\\nPercentual de Transações Fraudulentas (Treino vs Teste)\\n', fontsize=14, fontweight='bold')\n",
    "# for bar, pct in zip(bars, [train_fraud_pct, test_fraud_pct]):\n",
    "#     axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height()/2, f'{pct:.4f}%', ha='center', va='center', fontweight='bold', color='black', fontsize=12)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82277aba-7147-461a-a297-696ae2d51ee6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Criando um Experimento no ML Flow\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "201aa775-85a4-4fbf-83e1-d75cfd5d085c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nome_experimento = \"/Users/2106144@aluno.univesp.br/creditcard-fraud-detection\"\n",
    "\n",
    "try:\n",
    "    mlflow.create_experiment(nome_experimento)\n",
    "    print(f\"Novo experimento criado: {nome_experimento}\")\n",
    "except:\n",
    "    print(f\"Usando experimento existente: {nome_experimento}\")\n",
    "\n",
    "mlflow.set_experiment(nome_experimento)\n",
    "print(\"MLflow configurado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71e0237c-03ab-44f9-be4b-5f7044c03767",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Registra a divisão final no ML Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ed6c3a41-cac3-405e-81d7-091ac5cd8bf5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "923fc4e7-29ee-4a43-9c87-dccea5d22c5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(validation_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5fde7e31-c373-4cb7-bbed-0630d0f15cb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"divisao_final_treino_teste\"):\n",
    "    \n",
    "    mlflow.log_params({\n",
    "        \"proporcao_teste\": 0.2,\n",
    "        \"seed\": 42,\n",
    "        \"estratificacao\": True,\n",
    "        \"metodo_escolhido\": comparison['best_method'],\n",
    "        \"tabela_treino\": tabela_treino,\n",
    "        \"tabela_teste\": tabela_teste\n",
    "    })\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"tamanho_treino\": validation_stats['train_size'],\n",
    "        \"tamanho_teste\": validation_stats['test_size'],\n",
    "        \"proporcao_fraudes_treino\": validation_stats['train_fraud_ratio'],\n",
    "        \"proporcao_fraudes_teste\": validation_stats['test_fraud_ratio'],\n",
    "        \"erro_estratificacao\": validation_stats['stratification_error']\n",
    "    })\n",
    "    \n",
    "    mlflow.set_tags({\n",
    "        \"projeto\": \"detecao_fraudes_tcc\",\n",
    "        \"fonte_dados\": \"unity_catalog\", \n",
    "        \"tipo_processamento\": \"divisao_final_treino_teste\"\n",
    "    })\n",
    "    \n",
    "    print(\"Registrado no MLflow! :)\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 1 - Separação Treino e Teste",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
