{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bb7585d-f5d5-42be-96f4-78cf052c3571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Configurações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8665d2a1-90f7-49ed-8b92-8e974dff21cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow>=3.0 --upgrade\n",
    "%pip install lightgbm xgboost catboost scikit-plot imbalanced-learn synapseml\n",
    "%pip install lightgbm\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "80dc69c8-66cf-465d-82ff-2c77614e787c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, \n",
    "    precision_score, recall_score, f1_score, \n",
    "    precision_recall_curve, classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "import mlflow.pyfunc\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b9dfcd-4bdc-4cf6-9cf8-18d1bc7966c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Stacking Essemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8ff1fe50-d89e-4a0e-8b4f-394909e75415",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled = spark.read.table(\"my_catalog.default.creditcard_x_train_scaled_tcc\").toPandas()\n",
    "X_test_scaled = spark.read.table(\"my_catalog.default.creditcard_x_test_scaled_tcc\").toPandas()\n",
    "\n",
    "y_train = spark.read.table(\"my_catalog.default.creditcard_train_pdd_tcc\").toPandas()[\"Class\"]\n",
    "y_test = spark.read.table(\"my_catalog.default.creditcard_test_pd_tcc\").toPandas()[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "04c1881f-0afd-4d3d-b444-0d2c2bd90b80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uris = {\n",
    "    \"XGBoost\": \"models:/workspace.default.creditcard-fraud-xgboost-optimized/1\",\n",
    "    \"RandomForest\": \"models:/workspace.default.creditcard-fraud-randomforest-smote/1\",\n",
    "    \"CatBoost\": \"models:/workspace.default.creditcard-fraud-catboost-optimized/1\",\n",
    "    \"LightGBM\": \"models:/workspace.default.creditcard-fraud-lightgbm-smote/1\",\n",
    "    \"MLP_Classifier\": \"models:/workspace.default.creditcard-fraud-mlp_classifier-optimized/1\"\n",
    "}\n",
    "\n",
    "base_models = {}\n",
    "for model_name, model_uri in model_uris.items():\n",
    "    model = mlflow.pyfunc.load_model(model_uri)\n",
    "    base_models[model_name] = model\n",
    "    print(f\"Modelo {model_name} carregado com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1e4f1f87-722d-4268-9f65-19bd92aaa510",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "train_base_predictions = {}\n",
    "for model_name, model in base_models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        train_base_predictions[model_name] = model.predict_proba(X_train_scaled)[:, 1]\n",
    "    else:\n",
    "        train_base_predictions[model_name] = model.predict(X_train_scaled)\n",
    "\n",
    "train_meta_features = pd.DataFrame(train_base_predictions)\n",
    "\n",
    "train_meta_features['Class'] = y_train\n",
    "\n",
    "test_base_predictions = {}\n",
    "for model_name, model in base_models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        test_base_predictions[model_name] = model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        test_base_predictions[model_name] = model.predict(X_test_scaled)\n",
    "\n",
    "test_meta_features = pd.DataFrame(test_base_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "965c16bd-a564-459b-9489-2e9ef1aa7bba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "meta_learner = LogisticRegression(class_weight='balanced', random_state=42, max_iter=1000)\n",
    "meta_learner.fit(train_meta_features.drop('Class', axis=1), train_meta_features['Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "bfdc42ae-af8c-4a71-80f0-9024d0c937bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y_pred_meta = meta_learner.predict(test_meta_features)\n",
    "y_prob_meta = meta_learner.predict_proba(test_meta_features)[:, 1]\n",
    "\n",
    "roc_auc_meta = roc_auc_score(y_test, y_prob_meta)\n",
    "avg_precision_meta = average_precision_score(y_test, y_prob_meta)\n",
    "precision_meta = precision_score(y_test, y_pred_meta, zero_division=0)\n",
    "recall_meta = recall_score(y_test, y_pred_meta)\n",
    "f1_meta = f1_score(y_test, y_pred_meta)\n",
    "\n",
    "print(f\"Stacking Ensemble - ROC-AUC: {roc_auc_meta:.4f}, Avg Precision: {avg_precision_meta:.4f}, Precision: {precision_meta:.4f}, Recall: {recall_meta:.4f}, F1-Score: {f1_meta:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7ede6727-9a93-41bd-a26c-0fe57366538d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nAjustes finos na regressão logística:\\n\")\n",
    "\n",
    "class_weights = [\n",
    "    'balanced',\n",
    "    {0: 1, 1: 5},\n",
    "    {0: 1, 1: 8},\n",
    "    {0: 1, 1: 10},\n",
    "    {0: 1, 1: 15},\n",
    "    {0: 1, 1: 20}\n",
    "]\n",
    "\n",
    "C_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "lr_results = []\n",
    "\n",
    "for weight in class_weights:\n",
    "    for C in C_values:\n",
    "        try:\n",
    "            lr = LogisticRegression(\n",
    "                C=C,\n",
    "                class_weight=weight,\n",
    "                random_state=42,\n",
    "                max_iter=1000,\n",
    "                solver='liblinear'\n",
    "            )\n",
    "            \n",
    "            lr.fit(train_meta_features.drop('Class', axis=1), train_meta_features['Class'])\n",
    "            \n",
    "            y_pred_lr = lr.predict(test_meta_features)\n",
    "            y_prob_lr = lr.predict_proba(test_meta_features)[:, 1]\n",
    "            \n",
    "            roc_auc = roc_auc_score(y_test, y_prob_lr)\n",
    "            avg_precision = average_precision_score(y_test, y_prob_lr)\n",
    "            precision = precision_score(y_test, y_pred_lr, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred_lr)\n",
    "            f1 = f1_score(y_test, y_pred_lr)\n",
    "            \n",
    "            lr_results.append({\n",
    "                'C': C,\n",
    "                'class_weight': str(weight),\n",
    "                'ROC-AUC': roc_auc,\n",
    "                'Avg Precision': avg_precision,\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1-Score': f1\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Erro com C={C}, weight={weight}: {e}\")\n",
    "\n",
    "lr_results_df = pd.DataFrame(lr_results)\n",
    "print(\"\\nMelhores configurações de Logistic Regression:\")\n",
    "print(lr_results_df.sort_values('F1-Score', ascending=False).head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "74eac286-d09e-4600-9634-619e4740cea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Melhor configuração:\")\n",
    "print(\"C: 0.001, class_weight: {0: 1, 1: 8}\")\n",
    "print(\"ROC-AUC: 0.9126, Avg Precision: 0.7877, Precision: 0.9268, Recall: 0.7755, F1-Score: 0.8444\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e826097-01c9-401e-8d2d-13d0afdc4283",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Modelo        | ROC-AUC | Avg Precision | Precision | Recall | F1-Score |\n",
    "|----------------|--------|---------------|-----------|--------|----------|\n",
    "| Stacking Ensemble          | 0.9126 | 0.7877        | 0.9268    | 0.7755 | 0.8444   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1a74a6da-94bc-40df-97c7-bc85478d60cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_meta_learner = LogisticRegression(\n",
    "    C=0.001,\n",
    "    class_weight={0: 1, 1: 8},\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "final_meta_learner.fit(train_meta_features.drop('Class', axis=1), train_meta_features['Class'])\n",
    "\n",
    "y_pred_final = final_meta_learner.predict(test_meta_features)\n",
    "y_prob_final = final_meta_learner.predict_proba(test_meta_features)[:, 1]\n",
    "\n",
    "roc_auc_final = roc_auc_score(y_test, y_prob_final)\n",
    "avg_precision_final = average_precision_score(y_test, y_prob_final)\n",
    "precision_final = precision_score(y_test, y_pred_final, zero_division=0)\n",
    "recall_final = recall_score(y_test, y_pred_final)\n",
    "f1_final = f1_score(y_test, y_pred_final)\n",
    "\n",
    "print(f\"Modelo final otimizado:\")\n",
    "print(f\"F1-Score: {f1_final:.4f} (Original: 0.8432)\")\n",
    "print(f\"Precision: {precision_final:.4f} (Original: 0.8966)\")\n",
    "print(f\"Recall: {recall_final:.4f} (Original: 0.7959)\")\n",
    "print(f\"Avg precision: {avg_precision_final:.4f}\")\n",
    "\n",
    "\n",
    "cm_final = confusion_matrix(y_test, y_pred_final)\n",
    "print(f\"\\nMatriz de Confusão Final:\")\n",
    "print(cm_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63eaa26b-5199-40a6-a53d-9814e7dfe921",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Salvar no MLFLow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1a0c1116-b22e-44a4-889d-808515eec2cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Users/2106144@aluno.univesp.br/creditcard-fraud-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fbd6e0aa-b240-454d-bb09-4e6e0cf6e90d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sample_input = pd.DataFrame({\n",
    "    name: [0.5] * len(base_models) for name in base_models.keys()\n",
    "})\n",
    "sample_output = final_meta_learner.predict_proba(sample_input)[:, 1]\n",
    "signature = infer_signature(sample_input, sample_output)\n",
    "\n",
    "with mlflow.start_run(run_name=\"stacking_ensemble_complete\") as run_complete:\n",
    "    class StackingEnsemble(mlflow.pyfunc.PythonModel):\n",
    "        def __init__(self, base_models, meta_learner):\n",
    "            self.base_models = base_models\n",
    "            self.meta_learner = meta_learner\n",
    "\n",
    "        def predict(\n",
    "            self, \n",
    "            context, \n",
    "            model_input: pd.DataFrame\n",
    "        ) -> np.ndarray:\n",
    "            meta_features = {}\n",
    "            for name, model in self.base_models.items():\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    meta_features[name] = model.predict_proba(model_input)[:, 1]\n",
    "                else:\n",
    "                    meta_features[name] = model.predict(model_input)\n",
    "            meta_df = pd.DataFrame(meta_features)\n",
    "            return self.meta_learner.predict_proba(meta_df)[:, 1]\n",
    "\n",
    "    ensemble_model = StackingEnsemble(base_models, final_meta_learner)\n",
    "\n",
    "    mlflow.pyfunc.log_model(\n",
    "        name=\"complete_stacking_ensemble\",\n",
    "        python_model=ensemble_model,\n",
    "        registered_model_name=\"workspace.default.creditcard-fraud-complete-stacking-ensemble\",\n",
    "        signature=signature\n",
    "    )\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        \"roc_auc\": roc_auc_final,\n",
    "        \"avg_precision\": avg_precision_final,\n",
    "        \"precision\": precision_final,\n",
    "        \"recall\": recall_final,\n",
    "        \"f1_score\": f1_final\n",
    "    })\n",
    "\n",
    "    print(f\"\\nEnsemble completo salvo com sucesso!\")\n",
    "    print(f\"Run ID: {run_complete.info.run_id}\")\n",
    "\n",
    "print(\"\\n Modelos Registrados\\n\")\n",
    "from mlflow.tracking import MlflowClient\n",
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e0a6668f-0efe-47be-8af5-3af2d870eb37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"workspace.default.creditcard-fraud-complete-stacking-ensemble\"\n",
    "try:\n",
    "    versions = client.search_model_versions(f\"name='{model_name}'\")\n",
    "    print(f\"\\n{model_name}: \\n\")\n",
    "    for v in versions:\n",
    "        print(f\" Versão {v.version} - {v.status} - {v.run_id}\\n\")\n",
    "except:\n",
    "    print(f\"\\n Modelo {model_name} não encontrado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85590d04-8350-4186-b8de-e9323ea1d91e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Desempenho Preditivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "643f38d5-ee59-4da2-adc9-117b9dfcfa2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    \"roc_auc\": roc_auc_final,\n",
    "    \"avg_precision\": avg_precision_final,\n",
    "    \"precision\": precision_final,\n",
    "    \"recall\": recall_final,\n",
    "    \"f1_score\": f1_final\n",
    "}\n",
    "\n",
    "normalized_metrics = {k: (v if v is not None else 0) for k, v in metrics.items()}\n",
    "\n",
    "weights = {\n",
    "    \"roc_auc\": 0.2,\n",
    "    \"avg_precision\": 0.25,\n",
    "    \"precision\": 0.15,\n",
    "    \"recall\": 0.2,\n",
    "    \"f1_score\": 0.2\n",
    "}\n",
    "\n",
    "stacking_score = sum(normalized_metrics[k] * weights[k] for k in metrics.keys())\n",
    "\n",
    "print(\"Análise das métricas do modelo Stacking:\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(f\"\\nScore combinado para problemas desbalanceados: {stacking_score:.4f}\")\n",
    "print(\"Use este score para comparar modelos: quanto maior, melhor o desempenho geral considerando desbalanceamento.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcf08193-5c2b-480d-a2af-fccb321774ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Resultado de Desempenho Preditivo do Modelo Stacking Ensemble**\n",
    "\n",
    "| Métrica         | roc_auc | avg_precision | precision | recall | f1_score | Score combinado |\n",
    "|-----------------|---------|---------------|-----------|--------|----------|-----------------|\n",
    "| Valor           | 0.9126  | 0.7877        | 0.9268    | 0.7755 | 0.8444   | 0.8425          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1bdae17-6f59-41fa-a455-b7c8077ef38c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Eficiência Computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "830a5870-acb5-4772-970f-e282e7129d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "n_runs = 10\n",
    "inference_times = []\n",
    "memory_usages = []\n",
    "cpu_percents = []\n",
    "num_threads_list = []\n",
    "\n",
    "for _ in range(n_runs):\n",
    "    start_time = time.time()\n",
    "    y_pred_final = final_meta_learner.predict(test_meta_features)\n",
    "    inference_time = time.time() - start_time\n",
    "    inference_times.append(inference_time)\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usages.append(process.memory_info().rss / (1024 * 1024))\n",
    "    cpu_percents.append(psutil.cpu_percent(interval=0.1))\n",
    "    num_threads_list.append(process.num_threads())\n",
    "\n",
    "ensemble_efficiency = {\n",
    "    \"model\": \"StackingEnsemble\",\n",
    "    \"inference_time_sec\": np.mean(inference_times),\n",
    "    \"memory_usage_mb\": np.mean(memory_usages),\n",
    "    \"cpu_percent\": np.mean(cpu_percents),\n",
    "    \"num_threads\": np.mean(num_threads_list)\n",
    "}\n",
    "\n",
    "mlflow.log_metric(\"ensemble_inference_time_sec\", ensemble_efficiency[\"inference_time_sec\"])\n",
    "mlflow.log_metric(\"ensemble_memory_usage_mb\", ensemble_efficiency[\"memory_usage_mb\"])\n",
    "mlflow.log_metric(\"ensemble_cpu_percent\", ensemble_efficiency[\"cpu_percent\"])\n",
    "mlflow.log_metric(\"ensemble_num_threads\", ensemble_efficiency[\"num_threads\"])\n",
    "\n",
    "ensemble_efficiency_df = pd.DataFrame([ensemble_efficiency])\n",
    "display(ensemble_efficiency_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4a177cac-c002-42da-9c9d-cd5c35c49bb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_inference_time = 5.0  # segundos\n",
    "max_memory_usage = 1024.0  # MB\n",
    "max_cpu_percent = 100.0\n",
    "max_num_threads = 16.0\n",
    "\n",
    "efficiency_metrics = {\n",
    "    \"inference_time_sec\": ensemble_efficiency[\"inference_time_sec\"],\n",
    "    \"memory_usage_mb\": ensemble_efficiency[\"memory_usage_mb\"],\n",
    "    \"cpu_percent\": ensemble_efficiency[\"cpu_percent\"],\n",
    "    \"num_threads\": ensemble_efficiency[\"num_threads\"]\n",
    "}\n",
    "\n",
    "efficiency_score = (\n",
    "    (1 - min(efficiency_metrics[\"inference_time_sec\"] / max_inference_time, 1)) * 0.4 +\n",
    "    (1 - min(efficiency_metrics[\"memory_usage_mb\"] / max_memory_usage, 1)) * 0.4 +\n",
    "    (1 - min(efficiency_metrics[\"cpu_percent\"] / max_cpu_percent, 1)) * 0.1 +\n",
    "    (1 - min(efficiency_metrics[\"num_threads\"] / max_num_threads, 1)) * 0.1\n",
    ")\n",
    "\n",
    "overall_score = stacking_score * 0.7 + efficiency_score * 0.3\n",
    "\n",
    "print(f\"Score de eficiência computacional: {efficiency_score:.4f}\")\n",
    "print(f\"Score combinado (trade-off): {overall_score:.4f}\")\n",
    "\n",
    "mlflow.log_metric(\"efficiency_score\", efficiency_score)\n",
    "mlflow.log_metric(\"overall_score\", overall_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7b756797-80e7-48b9-af57-a3f6d5e06474",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "metrics_row = Row(\n",
    "    model=\"StackingEnsemble\",\n",
    "    roc_auc=float(roc_auc_final),\n",
    "    avg_precision=float(avg_precision_final),\n",
    "    precision=float(precision_final),\n",
    "    recall=float(recall_final),\n",
    "    f1_score=float(f1_final),\n",
    "    weighted_score=float(stacking_score),\n",
    "    inference_time_sec=float(ensemble_efficiency[\"inference_time_sec\"]),\n",
    "    memory_usage_mb=float(ensemble_efficiency[\"memory_usage_mb\"]),\n",
    "    cpu_percent=float(ensemble_efficiency[\"cpu_percent\"]),\n",
    "    num_threads=float(ensemble_efficiency[\"num_threads\"]),\n",
    "    efficiency_score=float(efficiency_score),\n",
    "    overall_score=float(overall_score)\n",
    ")\n",
    "\n",
    "metrics_spark_df = spark.createDataFrame([metrics_row])\n",
    "\n",
    "metrics_spark_df.write.mode(\"append\").saveAsTable(\"my_catalog.default.stacking_final_metrics_10_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "31a2cb55-b8c1-4963-8d56-097ba238231e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_spark_df = spark.table(\"my_catalog.default.stacking_final_metrics_10_runs\")\n",
    "display(metrics_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d5284333-e9af-468e-bc22-bbc780aa2a58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "factors = [10, 50, 100]  # fatores a testar\n",
    "n_runs = 10  # 10 execuções por fator\n",
    "\n",
    "original_count = len(test_meta_features)\n",
    "\n",
    "for factor in factors:\n",
    "    print(f\"\\n--- Testando Stacking com fator {factor} ---\")\n",
    "    bigdata_test = pd.concat([test_meta_features] * factor, ignore_index=True)\n",
    "    bigdata_y_test = np.tile(y_test, factor)\n",
    "\n",
    "    inference_times_big = []\n",
    "    memory_usages_big = []\n",
    "    cpu_percents_big = []\n",
    "    num_threads_list_big = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.time()\n",
    "        _ = final_meta_learner.predict(bigdata_test)\n",
    "        inference_time = time.time() - start_time\n",
    "        inference_times_big.append(inference_time)\n",
    "\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_usages_big.append(process.memory_info().rss / (1024 * 1024))\n",
    "        cpu_percents_big.append(psutil.cpu_percent(interval=0.1))\n",
    "        num_threads_list_big.append(process.num_threads())\n",
    "\n",
    "    metrics_big = {\n",
    "        \"model\": f\"StackingEnsemble_BigData_Factor{factor}\",\n",
    "        \"inference_time_sec\": np.mean(inference_times_big),\n",
    "        \"memory_usage_mb\": np.mean(memory_usages_big),\n",
    "        \"cpu_percent\": np.mean(cpu_percents_big),\n",
    "        \"num_threads\": np.mean(num_threads_list_big),\n",
    "        \"factor\": factor,\n",
    "        \"total_records\": original_count * factor\n",
    "    }\n",
    "\n",
    "    mlflow.log_metric(f\"stacking_inference_time_sec_bigdata_factor{factor}\", metrics_big[\"inference_time_sec\"])\n",
    "    mlflow.log_metric(f\"stacking_memory_usage_mb_bigdata_factor{factor}\", metrics_big[\"memory_usage_mb\"])\n",
    "    mlflow.log_metric(f\"stacking_cpu_percent_bigdata_factor{factor}\", metrics_big[\"cpu_percent\"])\n",
    "    mlflow.log_metric(f\"stacking_num_threads_bigdata_factor{factor}\", metrics_big[\"num_threads\"])\n",
    "\n",
    "    efficiency_df_bigdata = pd.DataFrame([metrics_big])\n",
    "    display(efficiency_df_bigdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f1318a37-c373-4251-8691-22929692204f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, IntegerType\n",
    ")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"model\", StringType(), True),\n",
    "    StructField(\"inference_time_sec\", DoubleType(), True),\n",
    "    StructField(\"memory_usage_mb\", DoubleType(), True),\n",
    "    StructField(\"cpu_percent\", DoubleType(), True),\n",
    "    StructField(\"num_threads\", DoubleType(), True),\n",
    "    StructField(\"factor\", IntegerType(), True),\n",
    "    StructField(\"total_records\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "for factor in factors:\n",
    "    metrics_row_big = Row(\n",
    "        model=f\"StackingEnsemble_BigData_Factor{factor}\",\n",
    "        inference_time_sec=float(np.mean(inference_times_big)),\n",
    "        memory_usage_mb=float(np.mean(memory_usages_big)),\n",
    "        cpu_percent=float(np.mean(cpu_percents_big)),\n",
    "        num_threads=float(np.mean(num_threads_list_big)),\n",
    "        factor=int(factor),\n",
    "        total_records=int(original_count * factor)\n",
    "    )\n",
    "    metrics_spark_df_big = spark.createDataFrame([metrics_row_big], schema=schema)\n",
    "    metrics_spark_df_big.write.mode(\"append\").saveAsTable(\n",
    "        \"my_catalog.default.stacking_bigdata_metrics\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d1a2f311-ae30-46af-9c38-7796fa1fc49d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_bigdata_df = spark.table(\"my_catalog.default.stacking_bigdata_metrics\")\n",
    "display(metrics_bigdata_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 4 - Stacking Ensemble",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
