{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec8e7121-6581-43a3-b6d1-5d4b29223b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Engenharia de Features e Modelos de M.L\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2667c7c3-e4de-4414-8348-4f0e8d2850cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configuração Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "724e3ebc-c126-4bcc-b9fa-55247f840cf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow>=3.0 --upgrade\n",
    "%pip install lightgbm xgboost catboost scikit-plot imbalanced-learn synapseml\n",
    "%pip install lightgbm\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "6eaf7ddc-f506-4501-83dc-f28c7d9f17b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, roc_curve, auc, classification_report,\n",
    "    confusion_matrix, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, sin, cos, sqrt, log, abs, pi, when\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, RobustScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from mlflow.models import infer_signature\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d3673c52-b4d3-4eb1-9ab5-db7be4fa3be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"/Users/2106144@aluno.univesp.br/creditcard-fraud-detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "443a6eb8-b59b-4103-a625-53d7006ca991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_set = spark.read.table(\"my_catalog.default.creditcard_treino_tcc\")\n",
    "test_set = spark.read.table(\"my_catalog.default.creditcard_teste_tcc\")\n",
    "\n",
    "print(f\"Treino: {train_set.count():,} linhas, {len(train_set.columns)} colunas\")\n",
    "print(f\"Teste: {test_set.count():,} linhas, {len(test_set.columns)} colunas\")\n",
    "train_set.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "159e7340-42de-4f1e-b8ff-21f3fa44babe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Engenharia de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7395375a-eb76-489e-95a1-9238231f59b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    cria features derivadas baseadas na análise exploratória.\n",
    "    \"\"\"\n",
    "    # features temporais\n",
    "    df = df.withColumn(\"hour_of_day\", (col(\"Time\") / 3600).cast(\"int\") % 24)\n",
    "    df = df.withColumn(\"hour_sin\", sin(2 * pi() * col(\"hour_of_day\") / 24))\n",
    "    df = df.withColumn(\"hour_cos\", cos(2 * 3.14159 * col(\"hour_of_day\") / 24))\n",
    "\n",
    "    # interações baseadas em análise de correlação\n",
    "    df = df.withColumn(\"V12_V14_interaction\", col(\"V12\") * col(\"V14\"))\n",
    "    df = df.withColumn(\"V3_V10_interaction\", col(\"V3\") * col(\"V10\"))\n",
    "    df = df.withColumn(\"V1_V2_complex\", sqrt(col(\"V1\")**2 + col(\"V2\")**2))\n",
    "\n",
    "    # features estatísticas avançadas (PCA magnitude)\n",
    "    pca_cols = ['V1', 'V2', 'V3', 'V4', 'V7', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18']\n",
    "    squared_expr = None\n",
    "    for c in pca_cols:\n",
    "        if squared_expr is None:\n",
    "            squared_expr = col(c) * col(c)\n",
    "        else:\n",
    "            squared_expr = squared_expr + (col(c) * col(c))\n",
    "    df = df.withColumn(\"pca_magnitude\", sqrt(squared_expr))\n",
    "\n",
    "    # transformações não-lineares\n",
    "    df = df.withColumn(\"Amount_log\", log(col(\"Amount\") + 1))\n",
    "    df = df.withColumn(\"Amount_sqrt\", sqrt(col(\"Amount\") + 0.1))\n",
    "    df = df.withColumn(\"amount_to_mean_ratio\", col(\"Amount\") / 88.35)  # média do dataset\n",
    "    df = df.withColumn(\"v1_anomaly\", abs(col(\"V1\") - (-0.001)) / 1.96)  # baseado na distribuição\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f68d6118-c40e-4a24-88ec-32d662ab9f39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# aplica engenharia de features\n",
    "train_set_fe = create_features(train_set)\n",
    "test_set_fe = create_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3f78f816-fadb-4b1e-8c85-8ba44af4be76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# salva os DataFrames com features no Unity Catalog\n",
    "train_set_fe.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_treino_fe_tcc\")\n",
    "test_set_fe.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_teste_fe_tcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c0b11c1-be44-4991-bf92-ba57d62c087f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Features selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9cd5c9b8-24dc-4519-a368-364102717a80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "final_features = [\n",
    "    'V1', 'V2', 'V3', 'V4', 'V7', 'V10', 'V11', 'V12', 'V14', 'V16', 'V17', 'V18',\n",
    "    'hour_sin', 'hour_cos', 'V12_V14_interaction', 'V3_V10_interaction',\n",
    "    'V1_V2_complex', 'pca_magnitude', 'Amount_log', 'Amount_sqrt',\n",
    "    'amount_to_mean_ratio', 'v1_anomaly'\n",
    "]\n",
    "target_column = 'Class'\n",
    "\n",
    "print(f\"Total de features: {len(final_features)}\")\n",
    "print(\"Features selecionadas:\")\n",
    "for i, feature in enumerate(final_features, 1):\n",
    "    print(f\"{i:2d}. {feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e405a67c-9e40-453e-9a30-b6ea1f6ffcdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Balanceamento com pesos de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d595a457-351c-4e33-8c7a-61782956bdc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def calculate_class_weights(df, target_col):\n",
    "    class_counts_df = df.groupBy(target_col).count()\n",
    "    class_counts_list = class_counts_df.collect()\n",
    "    counts_dict = {row[target_col]: row['count'] for row in class_counts_list}\n",
    "    total = sum(counts_dict.values())\n",
    "    num_classes = len(counts_dict)\n",
    "    balanced_weights = {class_val: total / (num_classes * count) for class_val, count in counts_dict.items()}\n",
    "    return balanced_weights\n",
    "\n",
    "balanced_weights = calculate_class_weights(train_set_fe, 'Class')\n",
    "train_set_weighted = train_set_fe.withColumn(\n",
    "    \"class_weight\",\n",
    "    when(col(\"Class\") == 1, balanced_weights[1]).otherwise(balanced_weights[0])\n",
    ")\n",
    "\n",
    "print(f\"Pesos de classe aplicados: {balanced_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0e520c6-fc75-4dcc-a66d-7aa66f6a72c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_set_weighted.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_treino_weighted_tcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "193f42da-2ac4-4a8e-afe6-4664434e7f8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pré-processamento com RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f40b15ee-bb91-4d27-a916-cf964061b5b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=final_features, outputCol=\"features_raw\")\n",
    "scaler = RobustScaler(inputCol=\"features_raw\", outputCol=\"features\")\n",
    "preprocessing_pipeline = Pipeline(stages=[assembler, scaler])\n",
    "\n",
    "preprocessing_model = preprocessing_pipeline.fit(train_set_weighted)\n",
    "train_processed = preprocessing_model.transform(train_set_weighted)\n",
    "test_processed = preprocessing_model.transform(test_set_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "426ea326-2785-4508-9136-96aa7c060285",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_processed.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_treino_processed_tcc\")\n",
    "test_processed.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_teste_processed_tcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9d109fe2-225f-43d7-9d59-93fbaa156318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_pd = train_processed.select(*final_features, \"Class\", \"class_weight\").toPandas()\n",
    "test_pd = test_processed.select(*final_features, \"Class\").toPandas()\n",
    "\n",
    "X_train = train_pd[final_features]\n",
    "y_train = train_pd['Class']\n",
    "sample_weights = train_pd['class_weight']\n",
    "X_test = test_pd[final_features]\n",
    "y_test = test_pd['Class']\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  \n",
    "X_test_scaled = scaler.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7cb8bf3f-d3af-412e-a184-18fb8feb89bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=final_features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=final_features)\n",
    "X_train_df = pd.DataFrame(X_train, columns=final_features)\n",
    "X_test_df = pd.DataFrame(X_test, columns=final_features)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "\n",
    "X_train_scaled_sdf = spark.createDataFrame(X_train_scaled_df)\n",
    "X_test_scaled_sdf = spark.createDataFrame(X_test_scaled_df)\n",
    "train_sdf = spark.createDataFrame(pd.concat([X_train_df, y_train_df], axis=1))\n",
    "test_sdf = spark.createDataFrame(pd.concat([X_test_df, y_test_df], axis=1))\n",
    "\n",
    "X_train_scaled_sdf.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_x_train_scaled_tcc\")\n",
    "X_test_scaled_sdf.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_x_test_scaled_tcc\")\n",
    "train_sdf.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_train_pdd_tcc\")\n",
    "test_sdf.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.creditcard_test_pd_tcc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "338247bb-796e-42ea-b311-406452008b30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Teste n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "95480a1d-f2c0-477d-8371-60b3c93c120a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "linear_models = {\n",
    "    \"LogisticRegression\": LogisticRegression(class_weight='balanced', random_state=42, max_iter=200),\n",
    "    \"NaiveBayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "tree_models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=200)\n",
    "}\n",
    "\n",
    "gradient_boosting_models = {\n",
    "    \"LightGBM\": LGBMClassifier(class_weight='balanced', random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(scale_pos_weight=balanced_weights[1]/balanced_weights[0], random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "}\n",
    "\n",
    "neural_network_models = {\n",
    "    \"MLP_Classifier\": MLPClassifier(random_state=42, early_stopping=True)\n",
    "}\n",
    "\n",
    "models = {**linear_models, **tree_models, **gradient_boosting_models, **neural_network_models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3a8a5d5-4fde-4346-b5b8-4842ea9be529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Treinamento dos modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "1b49880d-f6cf-4888-b49f-dbf838d9f17b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "def train_and_evaluate(models_dict, use_sample_weight=True):\n",
    "    for model_name, model in models_dict.items():\n",
    "        with mlflow.start_run(run_name=model_name):\n",
    "            try:\n",
    "                \n",
    "                if model_name in [\"NaiveBayes\", \"MLP_Classifier\"]:\n",
    "                    model.fit(X_train_scaled, y_train)\n",
    "                elif use_sample_weight:\n",
    "                    model.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "                else:\n",
    "                    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "                \n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "                else:\n",
    "                    y_prob = y_pred\n",
    "\n",
    "                \n",
    "                roc_auc = roc_auc_score(y_test, y_prob)\n",
    "                avg_precision = average_precision_score(y_test, y_prob)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "                \n",
    "                results[model_name] = {\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'avg_precision': avg_precision,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1,\n",
    "                    'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "                }\n",
    "\n",
    "                \n",
    "                mlflow.log_metrics({\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'avg_precision': avg_precision,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1\n",
    "                })\n",
    "\n",
    "                \n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    name=model_name,\n",
    "                    input_example=X_test_scaled[:5]\n",
    "                )\n",
    "\n",
    "                print(f\"Modelo {model_name} treinado, avaliado e salvo com sucesso.\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao treinar {model_name}: {str(e)}\")\n",
    "                mlflow.log_param(\"error\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "84cd9fa8-e2a7-47ef-9903-33e34c42f016",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_and_evaluate(linear_models, use_sample_weight=False)\n",
    "\n",
    "train_and_evaluate(tree_models)\n",
    "\n",
    "train_and_evaluate(gradient_boosting_models)\n",
    "\n",
    "train_and_evaluate({\"MLP_Classifier\": neural_network_models[\"MLP_Classifier\"]}, use_sample_weight=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b6f7f6-3cd2-4c66-a4fc-5b948494a72f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(results).T\n",
    "comparison_df = comparison_df.sort_values('roc_auc', ascending=False)\n",
    "print(comparison_df[['roc_auc', 'avg_precision', 'precision', 'recall', 'f1_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "463a018e-3e73-4518-b359-42aac5eda0f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## _Fine-tuning_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28a0258a-1732-4a85-9393-8b2dd98f9559",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ajuste Fino de Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fe797a84-7e06-42dc-a049-d1d09795f253",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"LogisticRegression\": {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [6, 8, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'depth': [4, 6, 8]\n",
    "    },\n",
    "    \"MLP_Classifier\": {\n",
    "        'hidden_layer_sizes': [(64,), (64, 32), (128, 64, 32)],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'alpha': [0.0001, 0.001, 0.01]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "24a574c1-8cde-488d-8592-97cd1dd43eb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stats_df = (\n",
    "    train_set.groupBy(\"Class\")\n",
    "    .agg(\n",
    "        F.round(F.expr(\"percentile_approx(Amount, 0.5)\"), 2).alias(\"Mediana\"),\n",
    "        F.round(F.avg(\"Amount\"), 2).alias(\"Média\"),\n",
    "        F.round(F.stddev(\"Amount\"), 2).alias(\"Desvio Padrão\"),\n",
    "        F.round(F.stddev(\"Amount\") / F.avg(\"Amount\"), 2).alias(\"Coef. Variação\")\n",
    "    )\n",
    ")\n",
    "\n",
    "display(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d38a3f65-0f69-488e-bbff-2f672cc52ccc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Ajustando hiperparâmetros para {model_name}...\")\n",
    "    if model_name in params:\n",
    "        search = RandomizedSearchCV(model, params[model_name], cv=5, scoring='f1', n_iter=10, random_state=42)\n",
    "        if model_name in [\"NaiveBayes\", \"MLP_Classifier\"]:\n",
    "            search.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            search.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "        best_models[model_name] = search.best_estimator_\n",
    "        print(f\"Melhores parâmetros para {model_name}: {search.best_params_}\")\n",
    "    else:\n",
    "        best_models[model_name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85269959-2251-4544-aa10-4e9b6c5afbc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Modelo              | Hiperparâmetros Otimizados                                                                                  |\n",
    "|---------------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| Logistic Regression | C=100, penalty='l2', solver='liblinear'                                                                     |\n",
    "| Random Forest       | n_estimators=100, max_depth=None, min_samples_split=2                                                       |\n",
    "| XGBoost             | learning_rate=0.2, max_depth=8, n_estimators=300, subsample=0.9, colsample_bytree=1.0                       |\n",
    "| LightGBM            | learning_rate=0.2, max_depth=8, n_estimators=300, num_leaves=50                                            |\n",
    "| CatBoost            | learning_rate=0.1, depth=6, iterations=200                                                                  |\n",
    "| MLP Classifier      | hidden_layer_sizes=(64, 32), activation='tanh', solver='adam', alpha=0.001                                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "722876af-79bd-4410-a0e5-0f07e2412868",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"models:/creditcard-fraud-detection/\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "common_requirements = [\n",
    "    \"scikit-learn==1.6.1\",\n",
    "    \"cloudpickle==3.0.0\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\"\n",
    "]\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    registered_model_name = f\"creditcard-fraud-{model_name}-best\"\n",
    "    with mlflow.start_run(run_name=f\"{model_name}_best_{timestamp}\"):\n",
    "        \n",
    "        if model_name in params:\n",
    "            mlflow.log_dict(params[model_name], \"hyperparameters.json\")\n",
    "       \n",
    "        if hasattr(model, \"get_params\"):\n",
    "            mlflow.log_dict(model.get_params(), \"best_params.json\")\n",
    "        \n",
    "        X_sample = X_test_scaled[:5]\n",
    "        y_sample = model.predict(X_sample)\n",
    "        signature = infer_signature(X_sample, y_sample)\n",
    "        mlflow.sklearn.log_model(\n",
    "            sk_model=model,\n",
    "            registered_model_name=registered_model_name,\n",
    "            pip_requirements=common_requirements,\n",
    "            signature=signature,\n",
    "            input_example=X_sample\n",
    "        )\n",
    "        print(f\"Melhor modelo {model_name} registrado no Unity Catalog como: {registered_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0554e013-bc99-402e-a6f3-5836c18a7dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Calibração das Probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f5abe918-d9df-4c27-ba1c-0c3eb021011e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "calibrated_models = {}\n",
    "\n",
    "for model_name, model in best_models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        print(f\"Calibrando {model_name}...\")\n",
    "        calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=5)\n",
    "        if model_name in [\"NaiveBayes\", \"MLP_Classifier\"]:\n",
    "            calibrated_model.fit(X_train_scaled, y_train)\n",
    "        else:\n",
    "            calibrated_model.fit(X_train_scaled, y_train, sample_weight=sample_weights)\n",
    "        calibrated_models[model_name] = calibrated_model\n",
    "    else:\n",
    "        calibrated_models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "af30b637-ec43-402a-be04-447accc412d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_path = \"models:/creditcard-fraud-detection/\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "common_requirements = [\n",
    "    \"scikit-learn==1.6.1\",\n",
    "    \"cloudpickle==3.0.0\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\"\n",
    "]\n",
    "\n",
    "for model_name, model in calibrated_models.items():\n",
    "    registered_model_name = f\"creditcard-fraud-{model_name}-calibrated\"\n",
    "    \n",
    "    X_sample = X_test_scaled[:5]\n",
    "    y_sample = model.predict(X_sample)\n",
    "    signature = infer_signature(X_sample, y_sample)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        registered_model_name=registered_model_name,\n",
    "        pip_requirements=common_requirements,\n",
    "        signature=signature,\n",
    "        input_example=X_sample\n",
    "    )\n",
    "    print(f\"Modelo calibrado {model_name} registrado no Unity Catalog como: {registered_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df83f5a0-862f-4e63-8e67-53e367b358de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ajuste do Threshold de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4e5cf11a-6d70-4bb5-8532-35a003844ad7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_thresholds = {}\n",
    "\n",
    "for model_name, model in calibrated_models.items():\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        print(f\"Ajustando threshold para {model_name}...\")\n",
    "        y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "        best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "        best_thresholds[model_name] = best_threshold\n",
    "        print(f\"Melhor threshold para {model_name}: {best_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76098e97-9f17-494e-a494-0ec1acb97513",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Modelo              | Melhor Threshold |\n",
    "|---------------------|-----------------|\n",
    "| LogisticRegression  | 0.9914          |\n",
    "| NaiveBayes          | 0.1370          |\n",
    "| DecisionTree        | 0.5339          |\n",
    "| RandomForest        | 0.9871          |\n",
    "| LightGBM            | 0.5024          |\n",
    "| XGBoost             | 0.9958          |\n",
    "| CatBoost            | 0.9955          |\n",
    "| MLP_Classifier      | 0.3624          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ff7d3fd-85ba-4d4d-9d43-b7b5b6b5889a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "thresholds_artifact_name = f\"best_thresholds_{timestamp}.json\"\n",
    "\n",
    "with mlflow.start_run(run_name=f\"best_thresholds_{timestamp}\"):\n",
    "    mlflow.log_dict(best_thresholds, thresholds_artifact_name)\n",
    "    mlflow.log_param(\"description\", \"Best thresholds for each model after calibration and optimization\")\n",
    "    print(f\"Best thresholds saved to Unity Catalog as artifact: {thresholds_artifact_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bee8cb7-8f17-4d4d-8d4a-99109c753556",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Avaliação dos Modelos com os Novos Parâmetros e Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5f776723-bba5-4cc1-b73a-958ab91c7fe9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "results_2 = {}\n",
    "\n",
    "for model_name, model in calibrated_models.items():\n",
    "    print(f\"Avaliando {model_name}...\")\n",
    "\n",
    "    try:\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_optimized\"):\n",
    "            if model_name in best_thresholds:\n",
    "                y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "                y_pred = (y_prob >= best_thresholds[model_name]).astype(int)\n",
    "            else:\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                y_prob = y_pred if not hasattr(model, \"predict_proba\") else model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "            roc_auc = roc_auc_score(y_test, y_prob)\n",
    "            avg_precision = average_precision_score(y_test, y_prob)\n",
    "            precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "            results_2[model_name] = {\n",
    "                'roc_auc': roc_auc,\n",
    "                'avg_precision': avg_precision,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1,\n",
    "                'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "            }\n",
    "\n",
    "            \n",
    "            mlflow.log_metrics({\n",
    "                'roc_auc': roc_auc,\n",
    "                'avg_precision': avg_precision,\n",
    "                'precision': precision,\n",
    "                'recall': recall,\n",
    "                'f1_score': f1\n",
    "            })\n",
    "\n",
    "            \n",
    "            X_sample = X_test_scaled[:5]\n",
    "            y_sample = model.predict(X_sample)\n",
    "            signature = infer_signature(X_sample, y_sample)\n",
    "            mlflow.sklearn.log_model(\n",
    "                sk_model=model,\n",
    "                name=f\"{model_name}_optimized_model\",\n",
    "                signature=signature,\n",
    "                input_example=X_sample\n",
    "            )\n",
    "\n",
    "            print(f\"Modelo {model_name} avaliado e salvo com sucesso.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao avaliar {model_name}: {str(e)}\")\n",
    "        if mlflow.active_run():\n",
    "            mlflow.end_run()\n",
    "        with mlflow.start_run(run_name=f\"{model_name}_optimized\"):\n",
    "            mlflow.log_param(\"error\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b17e6af0-5645-4763-b385-6bcb89c11c5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "comparison_df = pd.DataFrame(results_2).T\n",
    "comparison_df = comparison_df.sort_values('roc_auc', ascending=False)\n",
    "print(comparison_df[['roc_auc', 'avg_precision', 'precision', 'recall', 'f1_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af8ff41a-c40a-483c-8267-3e3b7e72a608",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91b9f50a-b1ee-4be6-b9c7-59e1b6512eb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_train_smote_tomek, y_train_smote_tomek = smote_tomek.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02f9ba22-fdd4-4e92-aef5-c641ecb0ce24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, BorderlineSMOTE\n",
    "adasyn = ADASYN(random_state=42)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7f19296d-c0dd-413d-9f7a-e726e95a2273",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_balancing(X_train_balanced, y_train_balanced, balancing_name):\n",
    "    results_smote_2 = {}\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"Avaliando {model_name} com {balancing_name}...\")\n",
    "        try:\n",
    "            with mlflow.start_run(run_name=f\"{model_name}_{balancing_name}\"):\n",
    "                \n",
    "                model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "                \n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "                else:\n",
    "                    y_prob = y_pred\n",
    "\n",
    "                \n",
    "                roc_auc = roc_auc_score(y_test, y_prob)\n",
    "                avg_precision = average_precision_score(y_test, y_prob)\n",
    "                precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "                recall = recall_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "                \n",
    "                results_smote_2[model_name] = {\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'avg_precision': avg_precision,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1,\n",
    "                    'tn': tn, 'fp': fp, 'fn': fn, 'tp': tp\n",
    "                }\n",
    "\n",
    "                \n",
    "                mlflow.log_metrics({\n",
    "                    'roc_auc': roc_auc,\n",
    "                    'avg_precision': avg_precision,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'f1_score': f1\n",
    "                })\n",
    "\n",
    "                \n",
    "                X_sample = X_test_scaled[:5]\n",
    "                y_sample = model.predict(X_sample)\n",
    "                signature = infer_signature(X_sample, y_sample)\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    name=f\"{model_name}_{balancing_name}_model\",\n",
    "                    signature=signature,\n",
    "                    input_example=X_sample\n",
    "                )\n",
    "\n",
    "                print(f\"Modelo {model_name} treinado, avaliado e salvo com sucesso.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao avaliar {model_name} com {balancing_name}: {str(e)}\")\n",
    "            if mlflow.active_run():\n",
    "                mlflow.end_run()\n",
    "            with mlflow.start_run(run_name=f\"{model_name}_{balancing_name}\"):\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "\n",
    "    return results_smote_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e43b1735-da53-4103-ad04-2f1c9326ff1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_no_balancing = train_and_evaluate_with_balancing(X_train_scaled, y_train, \"NoBalancing\")\n",
    "\n",
    "results_smote = train_and_evaluate_with_balancing(X_train_smote, y_train_smote, \"SMOTE\")\n",
    "\n",
    "results_smote_tomek = train_and_evaluate_with_balancing(X_train_smote_tomek, y_train_smote_tomek, \"SMOTETomek\")\n",
    "\n",
    "results_adasyn = train_and_evaluate_with_balancing(X_train_adasyn, y_train_adasyn, \"ADASYN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "08486781-a957-4403-a9b5-386e8cba8e3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "\n",
    "df_no_balancing = pd.DataFrame(results_no_balancing).T\n",
    "df_smote = pd.DataFrame(results_smote).T\n",
    "df_smote_tomek = pd.DataFrame(results_smote_tomek).T\n",
    "df_adasyn = pd.DataFrame(results_adasyn).T\n",
    "\n",
    "df_no_balancing['balancing'] = 'NoBalancing'\n",
    "df_smote['balancing'] = 'SMOTE'\n",
    "df_smote_tomek['balancing'] = 'SMOTETomek'\n",
    "df_adasyn['balancing'] = 'ADASYN'\n",
    "\n",
    "df_comparison = pd.concat([df_no_balancing, df_smote, df_smote_tomek, df_adasyn])\n",
    "df_comparison.reset_index(inplace=True)\n",
    "df_comparison.rename(columns={'index': 'model'}, inplace=True)\n",
    "\n",
    "cols = ['model', 'balancing', 'roc_auc', 'avg_precision', 'precision', 'recall', 'f1_score']\n",
    "df_comparison = df_comparison[cols]\n",
    "\n",
    "display(df_comparison.sort_values(['model', 'balancing']))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 3 - Engenharia de Features e Testes de Modelos M.L",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
