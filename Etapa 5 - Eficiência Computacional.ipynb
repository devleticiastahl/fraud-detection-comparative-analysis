{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "604aa73e-3789-49f8-aef7-c8bf016c0289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Análises de Eficiência Computacional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a43693cd-f880-4450-9b43-66ecf2e89ca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Configurações Iniciais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "00c463f3-a2a3-4d60-bfb9-db105eb944eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==3.6.0 xgboost lightgbm catboost graphviz==0.21 memory_profiler\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "27d4e013-2944-422b-b136-9ceb90818302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8b85c2e9-2618-45e2-ba22-55d3ce66eddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled = spark.read.table(\"my_catalog.default.creditcard_x_train_scaled_tcc\").toPandas()\n",
    "X_test_scaled = spark.read.table(\"my_catalog.default.creditcard_x_test_scaled_tcc\").toPandas()\n",
    "y_train = spark.read.table(\"my_catalog.default.creditcard_train_pdd_tcc\").toPandas()[\"Class\"]\n",
    "y_test = spark.read.table(\"my_catalog.default.creditcard_test_pd_tcc\").toPandas()[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "01dca511-388a-4b60-a26a-2e4f25657f0d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_uris = {\n",
    "    \"XGBoost\": \"models:/workspace.default.creditcard-fraud-xgboost-optimized/1\",\n",
    "    \"RandomForest\": \"models:/workspace.default.creditcard-fraud-randomforest-smote/1\",\n",
    "    \"CatBoost\": \"models:/workspace.default.creditcard-fraud-catboost-optimized/1\",\n",
    "    \"LightGBM\": \"models:/workspace.default.creditcard-fraud-lightgbm-smote/1\",\n",
    "    \"MLP_Classifier\": \"models:/workspace.default.creditcard-fraud-mlp_classifier-optimized/1\",\n",
    "    \"DecisionTree\": \"models:/workspace.default.creditcard-fraud-decisiontree-optimized/1\",\n",
    "    \"Logistic_Regression\": \"models:/workspace.default.creditcard-logistic-regression-optimized/1\"    \n",
    "}\n",
    "models = {}\n",
    "for model_name, model_uri in model_uris.items():\n",
    "    try:\n",
    "        model = mlflow.pyfunc.load_model(model_uri)\n",
    "        models[model_name] = model\n",
    "        print(f\"Modelo {model_name} carregado com sucesso\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dc81a496-4a99-4989-aac2-6cb4f4e23b3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_mlflow_metrics(model_uris):\n",
    "    \"\"\"carrega as métricas armazenadas no MLflow Registry\"\"\"\n",
    "    mlflow_metrics = []\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    for model_name, model_uri in model_uris.items():\n",
    "        try:\n",
    "            model_version = model_uri.split('/')[-1]\n",
    "            model_path = model_uri.replace(f\"/{model_version}\", \"\")\n",
    "            model_name_registry = model_path.split('/')[-1]\n",
    "            \n",
    "            \n",
    "            versions = client.search_model_versions(f\"name='{model_name_registry}'\")\n",
    "            \n",
    "            version_obj = next((v for v in versions if str(v.version) == str(model_version)), None)\n",
    "            \n",
    "            if version_obj and getattr(version_obj, \"run_id\", None):\n",
    "                run_id = version_obj.run_id\n",
    "                run = client.get_run(run_id)\n",
    "                metrics = run.data.metrics\n",
    "                mlflow_metrics.append({\n",
    "                    'model': model_name,\n",
    "                    'roc_auc': metrics.get('test_roc_auc', metrics.get('roc_auc', 0)),\n",
    "                    'pr_auc': metrics.get('test_avg_precision', metrics.get('avg_precision', 0)),\n",
    "                    'precision': metrics.get('test_precision', metrics.get('precision', 0)),\n",
    "                    'recall': metrics.get('test_recall', metrics.get('recall', 0)),\n",
    "                    'f1_score': metrics.get('test_f1', metrics.get('f1_score', 0)),\n",
    "                    'source': 'mlflow'\n",
    "                })\n",
    "                print(f\"Métricas carregadas do MLflow para {model_name}\")\n",
    "            else:\n",
    "                \n",
    "                print(f\"Erro ao carregar métricas do MLflow para {model_name}: run_id não encontrado para versão {model_version}. Verifique se o modelo foi registrado corretamente no MLflow Model Registry e se a versão existe.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar métricas do MLflow para {model_name}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(mlflow_metrics)\n",
    "try:\n",
    "    mlflow_predictive_results = load_mlflow_metrics(model_uris)\n",
    "    print(\"\\nMétricas do MLflow carregadas com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"Não foi possível carregar métricas do MLflow: {e}\")\n",
    "    mlflow_predictive_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "fe8ba147-a076-4210-8f5c-cea11d8b4dd1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"model\":239},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762908662512}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Resultados preditivos carregados do MLflow\")\n",
    "display(mlflow_predictive_results)\n",
    "all_predictive_results = mlflow_predictive_results.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f92255e8-1c7b-44eb-8308-9f6c5da18768",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "278c053b-84bf-431d-81d1-bc58e0ff7c8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"roc_auc\": 0.2,\n",
    "    \"avg_precision\": 0.25,\n",
    "    \"precision\": 0.15,\n",
    "    \"recall\": 0.2,\n",
    "    \"f1_score\": 0.2\n",
    "}\n",
    "\n",
    "def calculate_weighted_score(row, weights):\n",
    "    metrics = {\n",
    "        \"roc_auc\": row.get(\"roc_auc\", 0),\n",
    "        \"avg_precision\": row.get(\"pr_auc\", 0),\n",
    "        \"precision\": row.get(\"precision\", 0),\n",
    "        \"recall\": row.get(\"recall\", 0),\n",
    "        \"f1_score\": row.get(\"f1_score\", 0)\n",
    "    }\n",
    "    normalized_metrics = {k: (v if v is not None else 0) for k, v in metrics.items()}\n",
    "    return sum(normalized_metrics[k] * weights[k] for k in metrics.keys())\n",
    "\n",
    "all_predictive_results[\"weighted_score\"] = all_predictive_results.apply(lambda row: calculate_weighted_score(row, weights), axis=1)\n",
    "\n",
    "print(\"Análise das métricas dos modelos:\")\n",
    "for idx, row in all_predictive_results.iterrows():\n",
    "    print(f\"\\nModelo: {row['model']}\")\n",
    "    print(f\"roc_auc: {row['roc_auc']:.4f}\")\n",
    "    print(f\"avg_precision: {row['pr_auc']:.4f}\")\n",
    "    print(f\"precision: {row['precision']:.4f}\")\n",
    "    print(f\"recall: {row['recall']:.4f}\")\n",
    "    print(f\"f1_score: {row['f1_score']:.4f}\")\n",
    "    print(f\"Score combinado para problemas desbalanceados: {row['weighted_score']:.4f}\")\n",
    "\n",
    "display(all_predictive_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a32792a-4a83-485a-948e-a234db10e40b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Model              | ROC AUC   | PR AUC    | Precision  | Recall    | F1-Score  | Source | Weighted Score |\n",
    "|--------------------|-----------|-----------|------------|-----------|-----------|--------|----------------|\n",
    "| XGBoost            | 0.9585    | 0.8145    | 0.9383     | 0.7755    | 0.8492    | mlflow | 0.8610         |\n",
    "| RandomForest       | 0.9660    | 0.8105    | 0.9059     | 0.7857    | 0.8415    | mlflow | 0.8572         |\n",
    "| CatBoost           | 0.9787    | 0.7721    | 0.9259     | 0.7653    | 0.8380    | mlflow | 0.8483         |\n",
    "| LightGBM           | 0.9698    | 0.7830    | 0.8387     | 0.7959    | 0.8168    | mlflow | 0.8381         |\n",
    "| MLP_Classifier     | 0.9754    | 0.7657    | 0.8941     | 0.7755    | 0.8306    | mlflow | 0.8418         |\n",
    "| DecisionTree       | 0.8978    | 0.7321    | 0.8837     | 0.7755    | 0.8261    | mlflow | 0.8155         |\n",
    "| Logistic_Regression| 0.9683    | 0.7357    | 0.8523     | 0.7653    | 0.8065    | mlflow | 0.8198         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4c2976a7-5871-487b-b70f-eddd61402501",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "stacking_row = pd.DataFrame([{\n",
    "    \"model\": \"Stacking_Ensemble\",\n",
    "    \"weighted_score\": 0.8425\n",
    "}])\n",
    "sorted_df = pd.concat([all_predictive_results, stacking_row], ignore_index=True).sort_values(\"weighted_score\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(sorted_df[\"model\"], sorted_df[\"weighted_score\"], color='#ffcccc', edgecolor='none')\n",
    "plt.title(\"\\nScore de Desempenho Preditivo por Modelo\\n\", fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().yaxis.set_ticks([])\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "97d282d4-1539-4e68-bd2a-802d15c88618",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "efficiency_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    inference_time = time.time() - start_time\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "    memory_usage_mb = process.memory_info().rss / (1024 * 1024)\n",
    "    cpu_percent = psutil.cpu_percent(interval=1)\n",
    "    num_threads = process.num_threads()\n",
    "\n",
    "    efficiency_results.append({\n",
    "        \"model\": model_name,\n",
    "        \"inference_time_sec\": inference_time,\n",
    "        \"memory_usage_mb\": memory_usage_mb,\n",
    "        \"cpu_percent\": cpu_percent,\n",
    "        \"num_threads\": num_threads\n",
    "    })\n",
    "\n",
    "    mlflow.log_metric(f\"{model_name}_inference_time_sec\", inference_time)\n",
    "    mlflow.log_metric(f\"{model_name}_memory_usage_mb\", memory_usage_mb)\n",
    "    mlflow.log_metric(f\"{model_name}_cpu_percent\", cpu_percent)\n",
    "    mlflow.log_metric(f\"{model_name}_num_threads\", num_threads)\n",
    "\n",
    "efficiency_df = pd.DataFrame(efficiency_results)\n",
    "display(efficiency_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ec33a87b-3bd4-4f1e-a2b3-d3f402595401",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Com 10 runs, pegando a média dos runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "53186b70-1309-4804-9000-62093d53b94b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "n_runs = 10\n",
    "\n",
    "def run_efficiency_test(model, X):\n",
    "    inference_times = []\n",
    "    memory_usages = []\n",
    "    cpu_percents = []\n",
    "    num_threads_list = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.time()\n",
    "        _ = model.predict(X)\n",
    "        inference_time = time.time() - start_time\n",
    "        inference_times.append(inference_time)\n",
    "\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_usages.append(process.memory_info().rss / (1024 * 1024))\n",
    "        cpu_percents.append(psutil.cpu_percent(interval=0.1))\n",
    "        num_threads_list.append(process.num_threads())\n",
    "\n",
    "    return {\n",
    "        \"inference_time_sec\": np.mean(inference_times),\n",
    "        \"memory_usage_mb\": np.mean(memory_usages),\n",
    "        \"cpu_percent\": np.mean(cpu_percents),\n",
    "        \"num_threads\": np.mean(num_threads_list)\n",
    "    }\n",
    "\n",
    "efficiency_results = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    metrics = run_efficiency_test(model, X_test_scaled)\n",
    "    metrics[\"model\"] = model_name\n",
    "\n",
    "    mlflow.log_metric(f\"{model_name}_inference_time_sec\", metrics[\"inference_time_sec\"])\n",
    "    mlflow.log_metric(f\"{model_name}_memory_usage_mb\", metrics[\"memory_usage_mb\"])\n",
    "    mlflow.log_metric(f\"{model_name}_cpu_percent\", metrics[\"cpu_percent\"])\n",
    "    mlflow.log_metric(f\"{model_name}_num_threads\", metrics[\"num_threads\"])\n",
    "\n",
    "    efficiency_results.append(metrics)\n",
    "\n",
    "efficiency_df_10runs = pd.DataFrame(efficiency_results)\n",
    "display(efficiency_df_10runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "55a7b146-0d10-4151-9659-39c4e66293f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# valores de normalização e pesos dados as métricas podem e devem ser alterados de acordo com o caso e o que se deseja medir\n",
    "# definimos os valores abaixo considerando o contexto de detecção de fraude em cartão de crédito, onde é necessário equilibrar tempo de resposta rápido (inferência < 5s), uso moderado de memória (< 1GB), baixo consumo de CPU (< 100%) e número de threads (< 16), priorizando agilidade e escalabilidade em ambiente produtivo.\n",
    "\n",
    "# normalização dos valores de eficiência computacional\n",
    "max_inference_time = 5.0  # segundos\n",
    "max_memory_usage = 1024.0  # MB\n",
    "max_cpu_percent = 100.0\n",
    "max_num_threads = 16.0\n",
    "\n",
    "def compute_efficiency_score(row):\n",
    "    inference_time = row.get(\"inference_time_sec\", 0)\n",
    "    memory_usage_mb = row.get(\"memory_usage_mb\", 0)\n",
    "    cpu_percent = row.get(\"cpu_percent\", 0)\n",
    "    num_threads = row.get(\"num_threads\", 0)\n",
    "    score = (\n",
    "        (1 - min(inference_time / max_inference_time, 1)) * 0.4 +\n",
    "        (1 - min(memory_usage_mb / max_memory_usage, 1)) * 0.4 +\n",
    "        (1 - min(cpu_percent / max_cpu_percent, 1)) * 0.1 +\n",
    "        (1 - min(num_threads / max_num_threads, 1)) * 0.1\n",
    "    )\n",
    "    return score\n",
    "\n",
    "efficiency_df_10runs[\"efficiency_score\"] = efficiency_df_10runs.apply(compute_efficiency_score, axis=1)\n",
    "\n",
    "# score final de trade-off entre desempenho preditivo e eficiência computacional\n",
    "# pesos: 0.7 para weighted_score, 0.3 para efficiency_score\n",
    "\n",
    "merged_df = pd.merge(all_predictive_results, efficiency_df_10runs, on=\"model\")\n",
    "merged_df[\"overall_score\"] = merged_df[\"weighted_score\"] * 0.7 + merged_df[\"efficiency_score\"] * 0.3\n",
    "\n",
    "for idx, row in merged_df.iterrows():\n",
    "    print(f\"\\nModelo: {row['model']}\")\n",
    "    print(f\"Score de eficiência computacional: {row['efficiency_score']:.4f}\")\n",
    "    print(f\"Score combinado (trade-off): {row['overall_score']:.4f}\")\n",
    "    mlflow.log_metric(f\"{row['model']}_efficiency_score\", row['efficiency_score'])\n",
    "    mlflow.log_metric(f\"{row['model']}_overall_score\", row['overall_score'])\n",
    "\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dc7bfdaa-f424-429c-9c48-e42b4dbb729a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#from pyspark.sql import Row\n",
    "\n",
    "# cria lista de dicionários com todas as métricas dos modelos\n",
    "metrics_rows = []\n",
    "for idx, row in merged_df.iterrows():\n",
    "    metrics_rows.append(Row(\n",
    "        model=row['model'],\n",
    "        roc_auc=row['roc_auc'],\n",
    "        pr_auc=row['pr_auc'],\n",
    "        precision=row['precision'],\n",
    "        recall=row['recall'],\n",
    "        f1_score=row['f1_score'],\n",
    "        weighted_score=row['weighted_score'],\n",
    "        inference_time_sec=row['inference_time_sec'],\n",
    "        memory_usage_mb=row['memory_usage_mb'],\n",
    "        cpu_percent=row['cpu_percent'],\n",
    "        num_threads=row['num_threads'],\n",
    "        efficiency_score=row['efficiency_score'],\n",
    "        overall_score=row['overall_score'],\n",
    "        source=row.get('source', 'mlflow')\n",
    "    ))\n",
    "\n",
    "\n",
    "metrics_models_spark_df = spark.createDataFrame(metrics_rows)\n",
    "\n",
    "metrics_models_spark_df.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.final_model_metrics_all_10_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cc294220-070f-4aee-9957-46cb1d61db8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_models_df_10_runs = spark.table(\"my_catalog.default.final_model_metrics_all_10_runs\")\n",
    "display(metrics_models_df_10_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "cfedece9-0f36-49d8-bc5b-0a6027da9342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "metrics_stacking_df_10_runs = spark.table(\"my_catalog.default.stacking_final_metrics_10_runs\")\n",
    "display(metrics_stacking_df_10_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f285c31f-ff38-4f09-8462-cb0807e17deb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stacking_perf_row = metrics_stacking_df_10_runs.filter(metrics_stacking_df_10_runs[\"model\"] == \"StackingEnsemble\").toPandas().iloc[0]\n",
    "\n",
    "base_models = [\"XGBoost\", \"RandomForest\", \"CatBoost\", \"LightGBM\", \"MLP_Classifier\"]\n",
    "base_metrics = efficiency_df_10runs[efficiency_df_10runs[\"model\"].isin(base_models)].copy()\n",
    "\n",
    "total_inference_time = base_metrics[\"inference_time_sec\"].sum() + stacking_perf_row[\"inference_time_sec\"]\n",
    "max_memory_usage = max(base_metrics[\"memory_usage_mb\"].max(), stacking_perf_row[\"memory_usage_mb\"])\n",
    "max_num_threads = max(base_metrics[\"num_threads\"].max(), stacking_perf_row[\"num_threads\"])\n",
    "max_cpu_percent = max(base_metrics[\"cpu_percent\"].max(), stacking_perf_row[\"cpu_percent\"])\n",
    "\n",
    "max_inference_time = 5.0\n",
    "max_memory_usage_norm = 1024.0\n",
    "max_cpu_percent_norm = 100.0\n",
    "max_num_threads_norm = 16.0\n",
    "\n",
    "def compute_efficiency_score(row):\n",
    "    score = (\n",
    "        (1 - min(row[\"inference_time_sec\"] / max_inference_time, 1)) * 0.4 +\n",
    "        (1 - min(row[\"memory_usage_mb\"] / max_memory_usage_norm, 1)) * 0.4 +\n",
    "        (1 - min(row[\"cpu_percent\"] / max_cpu_percent_norm, 1)) * 0.1 +\n",
    "        (1 - min(row[\"num_threads\"] / max_num_threads_norm, 1)) * 0.1\n",
    "    )\n",
    "    return score\n",
    "\n",
    "stacking_efficiency_score = compute_efficiency_score({\n",
    "    \"inference_time_sec\": total_inference_time,\n",
    "    \"memory_usage_mb\": max_memory_usage,\n",
    "    \"cpu_percent\": max_cpu_percent,\n",
    "    \"num_threads\": max_num_threads\n",
    "})\n",
    "\n",
    "stacking_weighted_score = stacking_perf_row[\"weighted_score\"]\n",
    "precision = stacking_perf_row[\"precision\"]\n",
    "recall = stacking_perf_row[\"recall\"]\n",
    "stacking_pr_auc = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "stacking_overall_score = stacking_weighted_score * 0.7 + stacking_efficiency_score * 0.3\n",
    "\n",
    "stacking_final_row = pd.DataFrame([{\n",
    "    \"model\": \"StackingEnsemble\",\n",
    "    \"roc_auc\": stacking_perf_row[\"roc_auc\"],\n",
    "    \"pr_auc\": stacking_pr_auc,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall,\n",
    "    \"f1_score\": stacking_perf_row[\"f1_score\"],\n",
    "    \"weighted_score\": stacking_weighted_score,\n",
    "    \"inference_time_sec\": total_inference_time,\n",
    "    \"memory_usage_mb\": max_memory_usage,\n",
    "    \"cpu_percent\": max_cpu_percent,\n",
    "    \"num_threads\": max_num_threads,\n",
    "    \"efficiency_score\": stacking_efficiency_score,\n",
    "    \"overall_score\": stacking_overall_score,\n",
    "    \"source\": stacking_perf_row.get(\"source\", \"unity_catalog\")\n",
    "}])\n",
    "\n",
    "merged_df_with_stacking_10_runs = pd.concat([merged_df, stacking_final_row], ignore_index=True)\n",
    "merged_df_with_stacking_10_runs = merged_df_with_stacking_10_runs.sort_values(\"overall_score\", ascending=False).reset_index(drop=True)\n",
    "display(merged_df_with_stacking_10_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2a81f007-2a5a-4d77-ad96-17e00d9c972b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df_with_stacking_10_runs = pd.concat([merged_df, stacking_final_row], ignore_index=True)\n",
    "merged_df_with_stacking_10_runs = merged_df_with_stacking.sort_values(\"overall_score\", ascending=False).reset_index(drop=True)\n",
    "display(merged_df_with_stacking_10_runs)\n",
    "\n",
    "spark_df_with_stacking_10_runs = spark.createDataFrame(merged_df_with_stacking_10_runs)\n",
    "spark_df_with_stacking_10_runs.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.final_model_metrics_with_stacking_10_runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9c2f30c5-074a-454b-8a92-f0a0fe69cfb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "df = spark_df_with_stacking_10_runs.toPandas()\n",
    "df = df.sort_values(\"efficiency_score\", ascending=False)\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(df[\"model\"], df[\"efficiency_score\"], color='#cceeff', edgecolor='none')\n",
    "plt.title(\"\\nScore de Eficiência Computacional por Modelo no Volume Base (56.961 transações):\\n\", fontweight='bold')\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().set_yticks([])\n",
    "plt.gca().set_ylabel(\"\") \n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad1bc660-093c-458f-94dd-8d1d65884f6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "| Ranking | Modelo            | Tempo de Inferência (s) | Uso de Memória (MB) | Uso de CPU (%) | Nº Threads | Score Ef. Computacional |\n",
    "|---------|-------------------|-----------|--------------|---------|---------|------------------|\n",
    "| 1º      | CatBoost          | 0.094     | 699.79       | 16.35   | 30      | 0.603            |\n",
    "| 2º      | DecisionTree      | 0.022     | 701.80       | 24.25   | 30      | 0.600            |\n",
    "| 3º      | LightGBM          | 0.147     | 700.38       | 20.35   | 30      | 0.594            |\n",
    "| 4º      | LogisticRegression| 0.022     | 701.80       | 56.75   | 30      | 0.567            |\n",
    "| 5º      | RandomForest      | 0.560     | 699.65       | 22.45   | 30      | 0.559            |\n",
    "| 6º      | XGBoost           | 0.752     | 699.44       | 25.45   | 30      | 0.541            |\n",
    "| 7º      | MLP_Classifier    | 0.581     | 701.80       | 43.25   | 30      | 0.536            |\n",
    "| 8º      | StackingEnsemble  | 2.136     | 701.80       | 43.25   | 40      | 0.412            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23597464-2766-440c-aef1-b47ff3b11d2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Simulação de sobrecarga de dados para todos os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "715b6797-0da8-4a05-a8a3-2cee417f4e0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "original_count = len(X_test_scaled)\n",
    "display(original_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5b5b1605-c1cc-4911-ab3d-d89b813873d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# simulação de sobrecarga de dadospara todos os modelos\n",
    "factors = [10, 50, 100]  # fatores a testar\n",
    "n_runs = 10  #  10 execuções por fator\n",
    "\n",
    "original_count = len(X_test_scaled)\n",
    "\n",
    "for factor in factors:\n",
    "    print(f\"\\n--- Testando com fator {factor}) ---\")\n",
    "    bigdata_X_test = pd.concat([X_test_scaled] * factor, ignore_index=True)\n",
    "    bigdata_y_test = np.tile(y_test, factor)\n",
    "\n",
    "    efficiency_results_big = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        inference_times_big = []\n",
    "        memory_usages_big = []\n",
    "        cpu_percents_big = []\n",
    "        num_threads_list_big = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            start_time = time.time()\n",
    "            _ = model.predict(bigdata_X_test)\n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times_big.append(inference_time)\n",
    "\n",
    "            process = psutil.Process(os.getpid())\n",
    "            memory_usages_big.append(process.memory_info().rss / (1024 * 1024))\n",
    "            cpu_percents_big.append(psutil.cpu_percent(interval=0.1))\n",
    "            num_threads_list_big.append(process.num_threads())\n",
    "\n",
    "        metrics_big = {\n",
    "            \"model\": f\"{model_name}_BigData_Factor{factor}\",\n",
    "            \"inference_time_sec\": np.mean(inference_times_big),\n",
    "            \"memory_usage_mb\": np.mean(memory_usages_big),\n",
    "            \"cpu_percent\": np.mean(cpu_percents_big),\n",
    "            \"num_threads\": np.mean(num_threads_list_big),\n",
    "            \"factor\": factor,\n",
    "            \"total_records\": original_count * factor\n",
    "        }\n",
    "\n",
    "        mlflow.log_metric(f\"{model_name}_inference_time_sec_bigdata_factor{factor}\", metrics_big[\"inference_time_sec\"])\n",
    "        mlflow.log_metric(f\"{model_name}_memory_usage_mb_bigdata_factor{factor}\", metrics_big[\"memory_usage_mb\"])\n",
    "        mlflow.log_metric(f\"{model_name}_cpu_percent_bigdata_factor{factor}\", metrics_big[\"cpu_percent\"])\n",
    "        mlflow.log_metric(f\"{model_name}_num_threads_bigdata_factor{factor}\", metrics_big[\"num_threads\"])\n",
    "\n",
    "        efficiency_results_big.append(metrics_big)\n",
    "\n",
    "    efficiency_df_bigdata = pd.DataFrame(efficiency_results_big)\n",
    "    display(efficiency_df_bigdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "5dcb8b95-80fc-429a-987f-a2297acffe8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# salva resultados dos testes de eficiência dos modelos com fator 10, 50 e 100 no Unity Catalog\n",
    "for factor in factors:\n",
    "    bigdata_X_test = pd.concat([X_test_scaled] * factor, ignore_index=True)\n",
    "    bigdata_y_test = np.tile(y_test, factor)\n",
    "\n",
    "    efficiency_results_big = []\n",
    "    for model_name, model in models.items():\n",
    "        inference_times_big = []\n",
    "        memory_usages_big = []\n",
    "        cpu_percents_big = []\n",
    "        num_threads_list_big = []\n",
    "\n",
    "        for _ in range(n_runs):\n",
    "            start_time = time.time()\n",
    "            _ = model.predict(bigdata_X_test)\n",
    "            inference_time = time.time() - start_time\n",
    "            inference_times_big.append(inference_time)\n",
    "\n",
    "            process = psutil.Process(os.getpid())\n",
    "            memory_usages_big.append(process.memory_info().rss / (1024 * 1024))\n",
    "            cpu_percents_big.append(psutil.cpu_percent(interval=0.1))\n",
    "            num_threads_list_big.append(process.num_threads())\n",
    "\n",
    "        metrics_big = {\n",
    "            \"model\": f\"{model_name}_BigData_Factor{factor}\",\n",
    "            \"inference_time_sec\": np.mean(inference_times_big),\n",
    "            \"memory_usage_mb\": np.mean(memory_usages_big),\n",
    "            \"cpu_percent\": np.mean(cpu_percents_big),\n",
    "            \"num_threads\": np.mean(num_threads_list_big),\n",
    "            \"factor\": factor,\n",
    "            \"total_records\": len(bigdata_X_test)\n",
    "        }\n",
    "        efficiency_results_big.append(metrics_big)\n",
    "\n",
    "    efficiency_df_bigdata = pd.DataFrame(efficiency_results_big)\n",
    "    spark_df_bigdata = spark.createDataFrame(efficiency_df_bigdata)\n",
    "    spark_df_bigdata.write.mode(\"append\").saveAsTable(\"my_catalog.default.model_efficiency_bigdata_tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ef9cab24-3a98-4968-80a4-fab369a9b630",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#carregar dataset com stack para fator 10,50,100.\n",
    "metrics_bigdata_stacking_df = spark.table(\"my_catalog.default.stacking_bigdata_metrics\")\n",
    "display(metrics_bigdata_stacking_df)\n",
    "metrics_bigdata_all_models_df = spark.table(\"my_catalog.default.model_efficiency_bigdata_tests\")\n",
    "display(metrics_bigdata_all_models_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "84ed059f-afd6-48ee-be61-2491156b5f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_models = [\"XGBoost_BigData_Factor10\", \"RandomForest_BigData_Factor10\", \"CatBoost_BigData_Factor10\", \"LightGBM_BigData_Factor10\", \"MLP_Classifier_BigData_Factor10\",\n",
    "               \"XGBoost_BigData_Factor50\", \"RandomForest_BigData_Factor50\", \"CatBoost_BigData_Factor50\", \"LightGBM_BigData_Factor50\", \"MLP_Classifier_BigData_Factor50\",\n",
    "               \"XGBoost_BigData_Factor100\", \"RandomForest_BigData_Factor100\", \"CatBoost_BigData_Factor100\", \"LightGBM_BigData_Factor100\", \"MLP_Classifier_BigData_Factor100\"]\n",
    "\n",
    "stacking_df = spark.table(\"my_catalog.default.stacking_bigdata_metrics\").toPandas()\n",
    "all_models_df = spark.table(\"my_catalog.default.model_efficiency_bigdata_tests\").toPandas()\n",
    "\n",
    "stacking_rows = []\n",
    "for factor in [10, 50, 100]:\n",
    "    stacking_row = stacking_df[stacking_df[\"factor\"] == factor].iloc[0]\n",
    "    base_rows = all_models_df[(all_models_df[\"factor\"] == factor) & (all_models_df[\"model\"].str.contains(\"XGBoost|RandomForest|CatBoost|LightGBM|MLP_Classifier\"))]\n",
    "    total_inference_time = base_rows[\"inference_time_sec\"].sum() + stacking_row[\"inference_time_sec\"]\n",
    "    max_memory_usage = max(base_rows[\"memory_usage_mb\"].max(), stacking_row[\"memory_usage_mb\"])\n",
    "    max_cpu_percent = max(base_rows[\"cpu_percent\"].max(), stacking_row[\"cpu_percent\"])\n",
    "    max_num_threads = max(base_rows[\"num_threads\"].max(), stacking_row[\"num_threads\"])\n",
    "    stacking_rows.append({\n",
    "        \"model\": f\"StackingEnsemble_BigData_Factor{factor}\",\n",
    "        \"inference_time_sec\": total_inference_time,\n",
    "        \"memory_usage_mb\": max_memory_usage,\n",
    "        \"cpu_percent\": max_cpu_percent,\n",
    "        \"num_threads\": max_num_threads,\n",
    "        \"factor\": factor,\n",
    "        \"total_records\": stacking_row[\"total_records\"]\n",
    "    })\n",
    "\n",
    "stacking_realistic_df = pd.DataFrame(stacking_rows)\n",
    "all_models_with_stacking_df = pd.concat([all_models_df, stacking_realistic_df], ignore_index=True)\n",
    "display(all_models_with_stacking_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "8d1faf8e-5fec-41a0-8075-14c78b9cb7d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "stacking_realistic_df = pd.DataFrame(stacking_rows)\n",
    "all_models_with_stacking_df = pd.concat([all_models_df, stacking_realistic_df], ignore_index=True)\n",
    "spark_df_with_stacking = spark.createDataFrame(all_models_with_stacking_df)\n",
    "spark_df_with_stacking.write.mode(\"overwrite\").saveAsTable(\"my_catalog.default.model_efficiency_with_stacking_big_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "80b1e26a-b872-481e-9f12-ded097406c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_efficiency_with_stacking_big_data_df = spark.table(\"my_catalog.default.model_efficiency_with_stacking_big_data\")\n",
    "display(model_efficiency_with_stacking_big_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "dccaac49-92e3-41a4-a118-9fd9264e99ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model_efficiency_with_stacking_big_data_df = spark.table(\"my_catalog.default.model_efficiency_with_stacking_big_data\").toPandas()\n",
    "final_model_metrics_with_stacking_10_runs_df = spark.table(\"my_catalog.default.final_model_metrics_with_stacking_10_runs\").toPandas()\n",
    "\n",
    "original_count = len(X_test_scaled)\n",
    "\n",
    "predictive_metrics = final_model_metrics_with_stacking_10_runs_df.set_index(\"model\").to_dict(orient=\"index\")\n",
    "\n",
    "def get_prefix(model_name):\n",
    "    return model_name.split(\"_\")[0].lower()\n",
    "\n",
    "prefix_metrics = {}\n",
    "for model, metrics in predictive_metrics.items():\n",
    "    prefix = get_prefix(model)\n",
    "    prefix_metrics[prefix] = metrics\n",
    "\n",
    "for col in [\"roc_auc\", \"pr_auc\", \"precision\", \"recall\", \"f1_score\", \"weighted_score\"]:\n",
    "    model_efficiency_with_stacking_big_data_df[col] = model_efficiency_with_stacking_big_data_df[\"model\"].apply(\n",
    "        lambda x: prefix_metrics.get(get_prefix(x), {}).get(col, None)\n",
    "    )\n",
    "\n",
    "max_inference_time = 5.0\n",
    "max_memory_usage = 1024.0\n",
    "max_cpu_percent = 100.0\n",
    "max_num_threads = 16.0\n",
    "\n",
    "def compute_efficiency_score(row):\n",
    "    inference_time = row[\"inference_time_sec\"]\n",
    "    memory_usage_mb = row[\"memory_usage_mb\"]\n",
    "    cpu_percent = row[\"cpu_percent\"]\n",
    "    num_threads = row[\"num_threads\"]\n",
    "    score = (\n",
    "        (1 - min(inference_time / max_inference_time, 1)) * 0.4 +\n",
    "        (1 - min(memory_usage_mb / max_memory_usage, 1)) * 0.4 +\n",
    "        (1 - min(cpu_percent / max_cpu_percent, 1)) * 0.1 +\n",
    "        (1 - min(num_threads / max_num_threads, 1)) * 0.1\n",
    "    )\n",
    "    return score\n",
    "\n",
    "model_efficiency_with_stacking_big_data_df[\"efficiency_score\"] = model_efficiency_with_stacking_big_data_df.apply(compute_efficiency_score, axis=1)\n",
    "model_efficiency_with_stacking_big_data_df[\"overall_score\"] = (\n",
    "    model_efficiency_with_stacking_big_data_df[\"weighted_score\"] * 0.7 +\n",
    "    model_efficiency_with_stacking_big_data_df[\"efficiency_score\"] * 0.3\n",
    ")\n",
    "\n",
    "final_model_metrics_with_stacking_10_runs_df[\"factor\"] = 1\n",
    "final_model_metrics_with_stacking_10_runs_df[\"total_records\"] = original_count\n",
    "cols_to_add = [\"model\", \"inference_time_sec\", \"memory_usage_mb\", \"cpu_percent\", \"num_threads\", \"factor\", \"total_records\",\n",
    "               \"roc_auc\", \"pr_auc\", \"precision\", \"recall\", \"f1_score\", \"weighted_score\", \"efficiency_score\", \"overall_score\"]\n",
    "\n",
    "for col in cols_to_add:\n",
    "    if col not in final_model_metrics_with_stacking_10_runs_df.columns:\n",
    "        final_model_metrics_with_stacking_10_runs_df[col] = None\n",
    "\n",
    "df_final = pd.concat([model_efficiency_with_stacking_big_data_df[cols_to_add], final_model_metrics_with_stacking_10_runs_df[cols_to_add]], ignore_index=True)\n",
    "df_final = df_final.sort_values(\"model\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "spark_df_with_scores = spark.createDataFrame(df_final)\n",
    "display(spark_df_with_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cea000b0-fc47-4bf7-bedd-e1d0e08b7eae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_scores = spark.table(\"my_catalog.default.model_efficiency_with_scores\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e8659ed5-eb0b-41b9-9aaa-035d6666ab5c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763063951609}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_scores = df_scores.drop(columns=[col for col in [\"model_prefix\", \"modelo_base\"] if col in df_scores.columns])\n",
    "df_scores[\"model_name\"] = df_scores[\"model\"].apply(\n",
    "    lambda x: \"MLPClassifier\" if x.lower().startswith(\"mlp\") else (\"LogisticRegression\" if x.lower().startswith(\"logistic\") else x.split(\"_\")[0])\n",
    ")\n",
    "display(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "3ebc96d2-7f4c-44ef-991c-e3f086824749",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "factors = sorted(df_scores[\"factor\"].unique(), reverse=True)\n",
    "model_name = df_scores[\"model_name\"].unique()\n",
    "\n",
    "pivot_df = df_scores.pivot_table(index=\"model_name\", columns=\"factor\", values=\"efficiency_score\")\n",
    "\n",
    "plt.figure(figsize=(18, 10))\n",
    "plt.gca().set_facecolor('#f7f7f7')\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "\n",
    "bar_width = 0.25  \n",
    "space_between_bars = 0.1  \n",
    "group_spacing = 0.6  \n",
    "\n",
    "\n",
    "colors = plt.cm.tab10(np.linspace(0, 1, len(factors)))\n",
    "\n",
    "\n",
    "y_pos = np.arange(len(modelo_bases)) * (1 + group_spacing)\n",
    "\n",
    "\n",
    "for idx, factor in enumerate(factors):\n",
    "    scores = pivot_df[factor].values\n",
    "    x_pos = y_pos + idx * (bar_width + space_between_bars)\n",
    "    plt.barh(\n",
    "        x_pos,\n",
    "        scores,\n",
    "        height=bar_width,\n",
    "        color=colors[idx],\n",
    "        alpha=0.85,\n",
    "        label=f\"Fator {factor}\"\n",
    "    )\n",
    "    for i, score in enumerate(scores):\n",
    "        if not np.isnan(score):\n",
    "            \n",
    "            if idx < len(factors) - 1:  \n",
    "                prev_score = pivot_df[factors[idx + 1]].values[i]\n",
    "                variation = ((score - prev_score) / prev_score) * 100\n",
    "                label = f\"{score:.3f} ({variation:+.1f}%)\"\n",
    "            else:\n",
    "                label = f\"{score:.3f}\"\n",
    "            plt.text(\n",
    "                score,\n",
    "                x_pos[i],\n",
    "                label,\n",
    "                va='center',\n",
    "                ha='left',\n",
    "                fontsize=10,\n",
    "                color=colors[idx],\n",
    "                fontweight='bold'\n",
    "            )\n",
    "\n",
    "plt.yticks(y_pos + (len(factors) - 1) * (bar_width + space_between_bars) / 2, model_name, fontsize=12)\n",
    "\n",
    "plt.xlabel(\"\\nScore de Eficiência Computacional\", fontsize=10)\n",
    "plt.title(\"\\n Score de Eficiência Computacional por Modelo e Volume de Dados\\n\", fontweight='bold', fontsize=12)\n",
    "\n",
    "plt.legend(\n",
    "    title=\"Fator de Dados\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    "    fontsize=10,\n",
    "    title_fontsize=12\n",
    ")\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "plt.tight_layout(rect=[0, 0, 0.85, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "03055138-14e6-4a07-8642-18d9e620b3e1",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Modelo\":132,\"#row_number#\":52},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763066407486}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "for model in pivot_df.index:\n",
    "    score_1 = pivot_df.loc[model, 1] if 1 in pivot_df.columns else np.nan\n",
    "    score_100 = pivot_df.loc[model, 100] if 100 in pivot_df.columns else np.nan\n",
    "    if not np.isnan(score_1) and not np.isnan(score_100):\n",
    "        variation = ((score_100 - score_1) / score_1) * 100\n",
    "        summary.append({\n",
    "            \"Modelo\": model,\n",
    "            \"Score Fator 1\": f\"{score_1:.3f}\",\n",
    "            \"Score Fator 100\": f\"{score_100:.3f}\",\n",
    "            \"Variação (%)\": f\"{variation:+.1f}\",\n",
    "            \"var_num\": variation \n",
    "        })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df = summary_df.sort_values(\"var_num\", ascending=True).drop(columns=\"var_num\").reset_index(drop=True)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a60769e6-a4ea-406e-a837-e7261001aefb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Score de Eficiência Computacional por Modelo e Volume de Dados**\n",
    "| Modelo            | Score Fator 1 | Score Fator 100 | Variação (%) |\n",
    "|-------------------|--------------|-----------------|--------------|\n",
    "| MLPClassifier     | 0.536        | 0.062           | -88.4        |\n",
    "| LightGBM          | 0.594        | 0.076           | -87.2        |\n",
    "| StackingEnsemble  | 0.412        | 0.054           | -86.8        |\n",
    "| CatBoost          | 0.603        | 0.086           | -85.7        |\n",
    "| XGBoost           | 0.541        | 0.081           | -85.1        |\n",
    "| RandomForest      | 0.559        | 0.087           | -84.5        |\n",
    "| DecisionTree      | 0.600        | 0.309           | -48.5        |\n",
    "| LogisticRegression| 0.567        | 0.353           | -37.7        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fbbb43aa-9e20-4473-aae9-e2522ef97227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Score de Eficiência Computacional por Modelo e Volume de Dados**\n",
    "| Modelo            | Score Fator 1 | Score Fator 100 | Variação (%) |\n",
    "|-------------------|--------------|-----------------|--------------|\n",
    "| LogisticRegression| 0.567        | 0.353           | -37.7        |\n",
    "| DecisionTree      | 0.600        | 0.309           | -48.5        |\n",
    "| RandomForest      | 0.559        | 0.087           | -84.5        |\n",
    "| XGBoost           | 0.541        | 0.081           | -85.1        |\n",
    "| CatBoost          | 0.603        | 0.086           | -85.7        |\n",
    "| StackingEnsemble  | 0.412        | 0.054           | -86.8        |\n",
    "| LightGBM          | 0.594        | 0.076           | -87.2        |\n",
    "| MLPClassifier     | 0.536        | 0.062           | -88.4        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a15640f6-03ea-4970-84fa-5d1199471f8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "best_by_factor = []S\n",
    "for factor in sorted(pivot_df.columns):\n",
    "    best_model = pivot_df[factor].idxmax()\n",
    "    best_score = pivot_df[factor].max()\n",
    "    best_by_factor.append({\n",
    "        \"Fator\": factor,\n",
    "        \"Melhor Modelo\": best_model,\n",
    "        \"Score Ef. Comp.\": f\"{best_score:.3f}\"\n",
    "    })\n",
    "\n",
    "best_by_factor_df = pd.DataFrame(best_by_factor)\n",
    "\n",
    "mean_scores = pivot_df.mean(axis=1)\n",
    "top3 = mean_scores.sort_values(ascending=False).head(3)\n",
    "top3_df = pd.DataFrame({\n",
    "    \"Top 3 Modelos Gerais\": top3.index,\n",
    "    \"Score Ef. Comp. Médio Geral\": top3.map(lambda x: f\"{x:.3f}\").values\n",
    "})\n",
    "\n",
    "display(best_by_factor_df)\n",
    "display(top3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e6bafc45-548c-4212-92a1-4a24ac897352",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Score Médio Geral de Eficiência Computacional por Modelo**\n",
    "| Ranking | Modelo             | Score Eficiência Médio | Análise                          |\n",
    "|---------|--------------------|-----------------------|----------------------------------|\n",
    "| 1º      | LogisticRegression | 0.474                 | Melhor escalabilidade geral      |\n",
    "| 2º      | DecisionTree       | 0.465                 | Equilíbrio eficiência-velocidade |\n",
    "| 3º      | CatBoost           | 0.325                 | Líder entre ensemble models      |\n",
    "| 4º      | LightGBM           | 0.300                 | Eficiência moderada              |\n",
    "| 5º      | RandomForest       | 0.225                 | Custo de bagging evidente        |\n",
    "| 6º      | MLPClassifier      | 0.220                 | Redes neurais ineficientes       |\n",
    "| 7º      | XGBoost            | 0.219                 | Alta complexidade penaliza       |\n",
    "| 8º      | StackingEnsemble   | 0.165                 | Maior custo computacional        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7ba19de3-e514-4bfa-88df-2eb0dc56253c",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763064789739}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pivot_overall = df_scores.pivot_table(index=\"model_name\", columns=\"factor\", values=\"overall_score\")\n",
    "\n",
    "summary_overall = []\n",
    "for model in pivot_overall.index:\n",
    "    score_1 = pivot_overall.loc[model, 1] if 1 in pivot_overall.columns else np.nan\n",
    "    score_100 = pivot_overall.loc[model, 100] if 100 in pivot_overall.columns else np.nan\n",
    "    if not np.isnan(score_1) and not np.isnan(score_100):\n",
    "        variation = ((score_100 - score_1) / score_1) * 100\n",
    "        summary_overall.append({\n",
    "            \"Modelo\": model,\n",
    "            \"Trade-off Fator 1\": f\"{score_1:.3f}\",\n",
    "            \"Trade-off Fator 100\": f\"{score_100:.3f}\",\n",
    "            \"Variação (%)\": f\"{variation:+.1f}\",\n",
    "            \"var_num\": variation\n",
    "        })\n",
    "\n",
    "summary_overall_df = pd.DataFrame(summary_overall)\n",
    "summary_overall_df = summary_overall_df.sort_values(\"var_num\", ascending=True).drop(columns=\"var_num\").reset_index(drop=True)\n",
    "display(summary_overall_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a3294c28-3b8e-484f-afa9-4d8ed0497c44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pivot_overall = df_scores.pivot_table(index=\"model_name\", columns=\"factor\", values=\"overall_score\")\n",
    "\n",
    "best_by_factor = []\n",
    "for factor in sorted(pivot_overall.columns):\n",
    "    best_model = pivot_overall[factor].idxmax()\n",
    "    best_score = pivot_overall[factor].max()\n",
    "    best_by_factor.append({\n",
    "        \"Fator\": factor,\n",
    "        \"Melhor Modelo\": best_model,\n",
    "        \"Score Trade-off\": f\"{best_score:.3f}\"\n",
    "    })\n",
    "\n",
    "best_by_factor_df = pd.DataFrame(best_by_factor)\n",
    "\n",
    "mean_scores = pivot_overall.mean(axis=1)\n",
    "top3 = mean_scores.sort_values(ascending=False).head(3)\n",
    "top3_df = pd.DataFrame({\n",
    "    \"Top 3 Modelos Gerais\": top3.index,\n",
    "    \"Score Trade-off Médio Geral\": top3.map(lambda x: f\"{x:.3f}\").values\n",
    "})\n",
    "\n",
    "display(best_by_factor_df)\n",
    "display(top3_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "02d967dd-497c-4a1b-9bd4-a905622b77af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Volume Base (Fator 1):**\n",
    "| Ranking | Modelo             | Score Desempenho Preditivo | Score Ef. Comp. | Trade-off |\n",
    "|---------|--------------------|---------------|------------------|--------------|\n",
    "| 1º      | CatBoost           | 0.848         | 0.603            | 0.775        |\n",
    "| 2º      | RandomForest       | 0.857         | 0.559            | 0.768        |\n",
    "| 3º      | XGBoost            | 0.861         | 0.541            | 0.765        |\n",
    "| 4º      | LightGBM           | 0.838         | 0.594            | 0.765        |\n",
    "| 5º      | MLP_Classifier     | 0.842         | 0.536            | 0.750        |\n",
    "| 6º      | LogisticRegression | 0.820         | 0.567            | 0.744        |\n",
    "| 7º      | DecisionTree       | 0.815         | 0.600            | 0.751        |\n",
    "| 8º      | StackingEnsemble   | 0.842         | 0.412            | 0.713        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5affde0-6611-43f4-8e82-4590e8d4ec02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Volume Escalado (Fator 100):**\n",
    "| Ranking | Modelo             | Trade-off | Variação vs Fator 1 |\n",
    "|---------|--------------------|--------------|---------------------|\n",
    "| 1º      | LogisticRegression | 0.680        | -8.6%               |\n",
    "| 2º      | DecisionTree       | 0.663        | -11.6%              |\n",
    "| 3º      | XGBoost            | 0.627        | -18.1%              |\n",
    "| 4º      | RandomForest       | 0.626        | -18.5%              |\n",
    "| 5º      | CatBoost           | 0.620        | -20.0%              |\n",
    "| 6º      | LightGBM           | 0.609        | -20.3%              |\n",
    "| 7º      | MLPClassifier      | 0.608        | -18.9%              |\n",
    "| 8º      | StackingEnsemble   | 0.606        | -15.0%              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "9bf7738c-4b00-4cb4-a0a2-0573edf88fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#import numpy as np\n",
    "\n",
    "mean_efficiency = df_scores.groupby(\"model_name\")[\"efficiency_score\"].mean().sort_values(ascending=False)\n",
    "mean_overall = df_scores.groupby(\"model_name\")[\"overall_score\"].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(mean_efficiency.index, mean_efficiency.values, color='#87ceeb')\n",
    "plt.title(\"\\nScore Médio Geral de Eficiência Computacional por Modelo\\n\", fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.tight_layout()\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(mean_overall.index, mean_overall.values, color='#90ee90')\n",
    "plt.title(\"\\nScore Médio Geral de Trade-off (Desempenho x Eficiência) por Modelo\\n\", fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "plt.gca().axes.get_yaxis().set_visible(False)\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"Modelo\")\n",
    "plt.tight_layout()\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, height, f\"{height:.4f}\", ha='center', va='bottom', fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Etapa 5 - Eficiência Computacional",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
